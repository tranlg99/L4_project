{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# implementing code from https://github.com/aharley/pips"
      ],
      "metadata": {
        "id": "wvlokIvISftH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBVGaxcpOCHG"
      },
      "outputs": [],
      "source": [
        "# connecting drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/pips/')"
      ],
      "metadata": {
        "id": "iVGKiGcQOu6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing requirements\n",
        "!pip install imageio==2.19.3\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install tensorboardX==2.2\n",
        "!pip install einops==0.4.1\n",
        "!pip install scikit-learn==1.1.1\n",
        "!pip install matplotlib==3.5.1\n",
        "!pip install protobuf==3.20.0\n",
        "!pip install fire==0.4.0\n",
        "!pip install moviepy==1.0.3"
      ],
      "metadata": {
        "id": "tc90F7U_XaBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading their reference model\n",
        "!bash /content/drive/MyDrive/pips/get_reference_model.sh"
      ],
      "metadata": {
        "id": "p7xs1UPNZLEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import saverloader\n",
        "import imageio as imageio\n",
        "from nets.pips import Pips\n",
        "import utils.improc\n",
        "import random\n",
        "import glob\n",
        "from utils.basic import print_, print_stats\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "bOkESxjpUx_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "random.seed(125)\n",
        "np.random.seed(125)\n",
        "\n",
        "def run_model(model, rgbs, N, sw):\n",
        "    rgbs = rgbs.cuda().float() # B, S, C, H, W\n",
        "\n",
        "    B, S, C, H, W = rgbs.shape\n",
        "    rgbs_ = rgbs.reshape(B*S, C, H, W)\n",
        "    H_, W_ = 360, 640\n",
        "    rgbs_ = F.interpolate(rgbs_, (H_, W_), mode='bilinear')\n",
        "    H, W = H_, W_\n",
        "    rgbs = rgbs_.reshape(B, S, C, H, W)\n",
        "\n",
        "    # pick N points to track; we'll use a uniform grid\n",
        "    N_ = np.sqrt(N).round().astype(np.int32)\n",
        "    grid_y, grid_x = utils.basic.meshgrid2d(B, N_, N_, stack=False, norm=False, device='cuda')\n",
        "    grid_y = 8 + grid_y.reshape(B, -1)/float(N_-1) * (H-16)\n",
        "    grid_x = 8 + grid_x.reshape(B, -1)/float(N_-1) * (W-16)\n",
        "    xy = torch.stack([grid_x, grid_y], dim=-1) # B, N_*N_, 2\n",
        "    _, S, C, H, W = rgbs.shape\n",
        "\n",
        "    print_stats('rgbs', rgbs)\n",
        "    preds, preds_anim, vis_e, stats = model(xy, rgbs, iters=6)\n",
        "    trajs_e = preds[-1]\n",
        "    print_stats('trajs_e', trajs_e)\n",
        "    \n",
        "    pad = 50\n",
        "    rgbs = F.pad(rgbs.reshape(B*S, 3, H, W), (pad, pad, pad, pad), 'constant', 0).reshape(B, S, 3, H+pad*2, W+pad*2)\n",
        "    trajs_e = trajs_e + pad\n",
        "    \n",
        "    if sw is not None and sw.save_this:\n",
        "        linewidth = 2\n",
        "\n",
        "        # visualize the input\n",
        "        o1 = sw.summ_rgbs('inputs/rgbs', utils.improc.preprocess_color(rgbs[0:1]).unbind(1))\n",
        "        # visualize the trajs overlaid on the rgbs\n",
        "        o2 = sw.summ_traj2ds_on_rgbs('outputs/trajs_on_rgbs', trajs_e[0:1], utils.improc.preprocess_color(rgbs[0:1]), cmap='spring', linewidth=linewidth)\n",
        "        # visualize the trajs alone\n",
        "        o3 = sw.summ_traj2ds_on_rgbs('outputs/trajs_on_black', trajs_e[0:1], torch.ones_like(rgbs[0:1])*-0.5, cmap='spring', linewidth=linewidth)\n",
        "        # concat these for a synced wide vis\n",
        "        wide_cat = torch.cat([o1, o2, o3], dim=-1)\n",
        "        sw.summ_rgbs('outputs/wide_cat', wide_cat.unbind(1))\n",
        "\n",
        "        # write to disk, in case that's more convenient\n",
        "        wide_list = list(wide_cat.unbind(1))\n",
        "        wide_list = [wide[0].permute(1,2,0).cpu().numpy() for wide in wide_list]\n",
        "        wide_list = [Image.fromarray(wide) for wide in wide_list]\n",
        "        out_fn = './out_%d.gif' % sw.global_step\n",
        "        wide_list[0].save(out_fn, save_all=True, append_images=wide_list[1:])\n",
        "        print('saved %s' % out_fn)\n",
        "\n",
        "        # alternate vis\n",
        "        sw.summ_traj2ds_on_rgbs2('outputs/trajs_on_rgbs2', trajs_e[0:1], vis_e[0:1], utils.improc.preprocess_color(rgbs[0:1]))\n",
        "        \n",
        "        # animation of inference iterations\n",
        "        rgb_vis = []\n",
        "        for trajs_e_ in preds_anim:\n",
        "            trajs_e_ = trajs_e_ + pad\n",
        "            rgb_vis.append(sw.summ_traj2ds_on_rgb('', trajs_e_[0:1], torch.mean(utils.improc.preprocess_color(rgbs[0:1]), dim=1), cmap='spring', linewidth=linewidth, only_return=True))\n",
        "        sw.summ_rgbs('outputs/animated_trajs_on_rgb', rgb_vis)\n",
        "\n",
        "    return trajs_e-pad\n",
        "    \n",
        "def run_demo():\n",
        "\n",
        "    # the idea in this file is to run the model on some demo images, and return some visualizations\n",
        "    \n",
        "    exp_name = '00' # (exp_name is used for logging notes that correspond to different runs)\n",
        "\n",
        "    init_dir = 'reference_model'\n",
        "\n",
        "    ## choose hyps\n",
        "    B = 1\n",
        "    S = 8\n",
        "    N = 16**2 # number of points to track\n",
        "\n",
        "    filenames = glob.glob('/content/drive/MyDrive/pips//demo_images/*.jpg')\n",
        "    filenames = sorted(filenames)\n",
        "    print('filenames', filenames)\n",
        "    max_iters = len(filenames)//S # run each unique subsequence\n",
        "\n",
        "    log_freq = 2 # when to produce visualizations \n",
        "    \n",
        "    ## autogen a name\n",
        "    model_name = \"%02d_%d_%d\" % (B, S, N)\n",
        "    model_name += \"_%s\" % exp_name\n",
        "    import datetime\n",
        "    model_date = datetime.datetime.now().strftime('%H:%M:%S')\n",
        "    model_name = model_name + '_' + model_date\n",
        "    print('model_name', model_name)\n",
        "    \n",
        "    log_dir = 'logs_demo'\n",
        "    writer_t = SummaryWriter(log_dir + '/' + model_name + '/t', max_queue=10, flush_secs=60)\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "    model = Pips(stride=4).cuda()\n",
        "    parameters = list(model.parameters())\n",
        "    if init_dir:\n",
        "        _ = saverloader.load(init_dir, model)\n",
        "    global_step = 0\n",
        "    model.eval()\n",
        "\n",
        "    print(global_step)\n",
        "    print(max_iters)\n",
        "    while global_step < max_iters:\n",
        "        \n",
        "        read_start_time = time.time()\n",
        "        \n",
        "        global_step += 1\n",
        "\n",
        "        sw_t = utils.improc.Summ_writer(\n",
        "            writer=writer_t,\n",
        "            global_step=global_step,\n",
        "            log_freq=log_freq,\n",
        "            fps=5,\n",
        "            scalar_freq=int(log_freq/2),\n",
        "            just_gif=True)\n",
        "\n",
        "        try:\n",
        "            rgbs = []\n",
        "            for s in range(S):\n",
        "                fn = filenames[(global_step-1)*S+s]\n",
        "                if s==0:\n",
        "                    print('start frame', fn)\n",
        "                im = imageio.imread(fn)\n",
        "                im = im.astype(np.uint8)\n",
        "                rgbs.append(torch.from_numpy(im).permute(2,0,1))\n",
        "            rgbs = torch.stack(rgbs, dim=0).unsqueeze(0) # 1, S, C, H, W\n",
        "\n",
        "            read_time = time.time()-read_start_time\n",
        "            iter_start_time = time.time()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                \n",
        "                trajs_e = run_model(model, rgbs, N, sw_t)\n",
        "\n",
        "            iter_time = time.time()-iter_start_time\n",
        "            print('%s; step %06d/%d; rtime %.2f; itime %.2f' % (\n",
        "                model_name, global_step, max_iters, read_time, iter_time))\n",
        "        except FileNotFoundError as e:\n",
        "            print('error', e)\n",
        "            \n",
        "    writer_t.close()"
      ],
      "metadata": {
        "id": "N5unQX_odFGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_demo()"
      ],
      "metadata": {
        "id": "NXkOKkFHkDVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n"
      ],
      "metadata": {
        "id": "Gf0ZUi5hlxjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs_demo"
      ],
      "metadata": {
        "id": "iAUi8QnWl0ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(125)\n",
        "np.random.seed(125)\n",
        "\n",
        "def run_model(model, rgbs, N, sw):\n",
        "    rgbs = rgbs.cuda().float() # B, S, C, H, W\n",
        "\n",
        "    B, S, C, H, W = rgbs.shape\n",
        "    rgbs_ = rgbs.reshape(B*S, C, H, W)\n",
        "    H_, W_ = 360, 640\n",
        "    rgbs_ = F.interpolate(rgbs_, (H_, W_), mode='bilinear')\n",
        "    H, W = H_, W_\n",
        "    rgbs = rgbs_.reshape(B, S, C, H, W)\n",
        "\n",
        "    # try to pick a point on the dog, so we get an interesting trajectory\n",
        "    # x = torch.randint(-10, 10, size=(1, N), device=torch.device('cuda')) + 468\n",
        "    # y = torch.randint(-10, 10, size=(1, N), device=torch.device('cuda')) + 118\n",
        "    x = torch.ones((1, N), device=torch.device('cuda')) * 450.0\n",
        "    y = torch.ones((1, N), device=torch.device('cuda')) * 100.0\n",
        "    xy0 = torch.stack([x, y], dim=-1) # B, N, 2\n",
        "    _, S, C, H, W = rgbs.shape\n",
        "\n",
        "    trajs_e = torch.zeros((B, S, N, 2), dtype=torch.float32, device='cuda')\n",
        "    for n in range(N):\n",
        "        # print('working on keypoint %d/%d' % (n+1, N))\n",
        "        cur_frame = 0\n",
        "        done = False\n",
        "        traj_e = torch.zeros((B, S, 2), dtype=torch.float32, device='cuda')\n",
        "        traj_e[:,0] = xy0[:,n] # B, 1, 2  # set first position \n",
        "        feat_init = None\n",
        "        while not done:\n",
        "            end_frame = cur_frame + 8\n",
        "\n",
        "            rgb_seq = rgbs[:,cur_frame:end_frame]\n",
        "            S_local = rgb_seq.shape[1]\n",
        "            rgb_seq = torch.cat([rgb_seq, rgb_seq[:,-1].unsqueeze(1).repeat(1,8-S_local,1,1,1)], dim=1)\n",
        "\n",
        "            outs = model(traj_e[:,cur_frame].reshape(1, -1, 2), rgb_seq, iters=6, feat_init=feat_init, return_feat=True)\n",
        "            preds = outs[0]\n",
        "            vis = outs[2] # B, S, 1\n",
        "            feat_init = outs[3]\n",
        "            \n",
        "            vis = torch.sigmoid(vis) # visibility confidence\n",
        "            xys = preds[-1].reshape(1, 8, 2)\n",
        "            traj_e[:,cur_frame:end_frame] = xys[:,:S_local]\n",
        "\n",
        "            found_skip = False\n",
        "            thr = 0.9\n",
        "            si_last = 8-1 # last frame we are willing to take\n",
        "            si_earliest = 1 # earliest frame we are willing to take\n",
        "            si = si_last\n",
        "            while not found_skip:\n",
        "                if vis[0,si] > thr:\n",
        "                    found_skip = True\n",
        "                else:\n",
        "                    si -= 1\n",
        "                if si == si_earliest:\n",
        "                    # print('decreasing thresh')\n",
        "                    thr -= 0.02\n",
        "                    si = si_last\n",
        "            # print('found skip at frame %d, where we have' % si, vis[0,si].detach().item())\n",
        "\n",
        "            cur_frame = cur_frame + si\n",
        "\n",
        "            if cur_frame >= S:\n",
        "                done = True\n",
        "        trajs_e[:,:,n] = traj_e\n",
        "    \n",
        "    pad = 50\n",
        "    rgbs = F.pad(rgbs.reshape(B*S, 3, H, W), (pad, pad, pad, pad), 'constant', 0).reshape(B, S, 3, H+pad*2, W+pad*2)\n",
        "    trajs_e = trajs_e + pad\n",
        "\n",
        "    prep_rgbs = utils.improc.preprocess_color(rgbs)\n",
        "    gray_rgbs = torch.mean(prep_rgbs, dim=2, keepdim=True).repeat(1, 1, 3, 1, 1)\n",
        "    \n",
        "    if sw is not None and sw.save_this:\n",
        "        linewidth = 2\n",
        "\n",
        "        for n in range(N):\n",
        "            # print('visualizing kp %d' % n)\n",
        "            kp_vis = sw.summ_traj2ds_on_rgbs('video_%d/kp_%d_trajs_e_on_rgbs' % (sw.global_step, n), trajs_e[0:1,:,n:n+1], gray_rgbs[0:1,:S], cmap='spring', linewidth=linewidth)\n",
        "\n",
        "            # write to disk, in case that's more convenient\n",
        "            kp_list = list(kp_vis.unbind(1))\n",
        "            kp_list = [kp[0].permute(1,2,0).cpu().numpy() for kp in kp_list]\n",
        "            kp_list = [Image.fromarray(kp) for kp in kp_list]\n",
        "            out_fn = './chain_out_%d.gif' % sw.global_step\n",
        "            kp_list[0].save(out_fn, save_all=True, append_images=kp_list[1:])\n",
        "            print('saved %s' % out_fn)\n",
        "            \n",
        "        sw.summ_traj2ds_on_rgb('outputs/trajs_e_on_rgb', trajs_e[0:1], prep_rgbs[0:1,0], cmap='spring')\n",
        "        sw.summ_traj2ds_on_rgb('outputs/trajs_e_on_rgb2', trajs_e[0:1], torch.mean(prep_rgbs[0:1], dim=1), cmap='spring')\n",
        "        \n",
        "\n",
        "    return trajs_e-pad\n",
        "    \n",
        "def run_chain_demo():\n",
        "\n",
        "    # the idea in this file is to chain together pips from a long sequence, and return some visualizations\n",
        "    \n",
        "    exp_name = '00' # (exp_name is used for logging notes that correspond to different runs)\n",
        "\n",
        "    init_dir = 'reference_model'\n",
        "\n",
        "    ## choose hyps\n",
        "    B = 1\n",
        "    S = 50\n",
        "    N = 1 # number of points to track\n",
        "\n",
        "    filenames = glob.glob('/content/drive/MyDrive/pips/demo_images/*.jpg')\n",
        "    filenames = sorted(filenames)\n",
        "    print('filenames', filenames)\n",
        "    max_iters = len(filenames)//(S//2)-1 # run slightly overlapping subseqs\n",
        "\n",
        "    log_freq = 1 # when to produce visualizations \n",
        "    \n",
        "    ## autogen a name\n",
        "    model_name = \"%02d_%d_%d\" % (B, S, N)\n",
        "    model_name += \"_%s\" % exp_name\n",
        "    import datetime\n",
        "    model_date = datetime.datetime.now().strftime('%H:%M:%S')\n",
        "    model_name = model_name + '_' + model_date\n",
        "    print('model_name', model_name)\n",
        "    \n",
        "    log_dir = 'logs_chain_demo'\n",
        "    writer_t = SummaryWriter(log_dir + '/' + model_name + '/t', max_queue=10, flush_secs=60)\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "    model = Pips(stride=4).cuda()\n",
        "    parameters = list(model.parameters())\n",
        "    if init_dir:\n",
        "        _ = saverloader.load(init_dir, model)\n",
        "    global_step = 0\n",
        "    model.eval()\n",
        "    \n",
        "    while global_step < max_iters:\n",
        "        \n",
        "        read_start_time = time.time()\n",
        "        \n",
        "        global_step += 1\n",
        "\n",
        "        sw_t = utils.improc.Summ_writer(\n",
        "            writer=writer_t,\n",
        "            global_step=global_step,\n",
        "            log_freq=log_freq,\n",
        "            fps=12,\n",
        "            scalar_freq=int(log_freq/2),\n",
        "            just_gif=True)\n",
        "\n",
        "        try:\n",
        "            rgbs = []\n",
        "            for s in range(S):\n",
        "                fn = filenames[(global_step-1)*S//2+s]\n",
        "                if s==0:\n",
        "                    print('start frame', fn)\n",
        "                im = imageio.imread(fn)\n",
        "                im = im.astype(np.uint8)\n",
        "                rgbs.append(torch.from_numpy(im).permute(2,0,1))\n",
        "            rgbs = torch.stack(rgbs, dim=0).unsqueeze(0) # 1, S, C, H, W\n",
        "\n",
        "            read_time = time.time()-read_start_time\n",
        "            iter_start_time = time.time()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                trajs_e = run_model(model, rgbs, N, sw_t)\n",
        "\n",
        "            iter_time = time.time()-iter_start_time\n",
        "            print('%s; step %06d/%d; rtime %.2f; itime %.2f' % (\n",
        "                model_name, global_step, max_iters, read_time, iter_time))\n",
        "        except FileNotFoundError as e:\n",
        "            print('error', e)\n",
        "            \n",
        "    writer_t.close()"
      ],
      "metadata": {
        "id": "G2KXP44_nHOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_chain_demo()\n",
        "# change"
      ],
      "metadata": {
        "id": "adTYugPPnZLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir logs_chain_demo"
      ],
      "metadata": {
        "id": "gaIR5Alcn39F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}