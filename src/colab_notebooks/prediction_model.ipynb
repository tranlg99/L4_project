{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning the modified model with our data"
      ],
      "metadata": {
        "id": "bn3RvCIca8I4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports\n"
      ],
      "metadata": {
        "id": "Pzg01dJvZX7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connecting drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8EsrI8UYlGq",
        "outputId": "1b9b015d-1d70-46f8-e761-4ede5126e0c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import numpy as np\n",
        "import torch\n",
        "import argparse\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import copy\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.io.image import read_image\n",
        "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/drive_folder')\n",
        "from custom_dataset_loader import TaiChiDataset, ToTensor"
      ],
      "metadata": {
        "id": "Bp5Dfv5mYtHW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "7pjuHO5HZhxE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PyfjK8dkYgUA"
      },
      "outputs": [],
      "source": [
        "# converting all the images to tensors and then normalize them\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def meshgrid2d(B, Y, X, stack=False, device='cuda'):\n",
        "    # returns a meshgrid sized B x Y x X\n",
        "\n",
        "    grid_y = torch.linspace(0.0, Y-1, Y, device=torch.device(device))\n",
        "    grid_y = torch.reshape(grid_y, [1, Y, 1])\n",
        "    grid_y = grid_y.repeat(B, 1, X)\n",
        "\n",
        "    grid_x = torch.linspace(0.0, X-1, X, device=torch.device(device))\n",
        "    grid_x = torch.reshape(grid_x, [1, 1, X])\n",
        "    grid_x = grid_x.repeat(B, Y, 1)\n",
        "\n",
        "    if stack:\n",
        "        # note we stack in xy order\n",
        "        # (see https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.grid_sample)\n",
        "        grid = torch.stack([grid_x, grid_y], dim=-1)\n",
        "        return grid\n",
        "    else:\n",
        "        return grid_y, grid_x\n",
        "\n",
        "def get_normalised_grid(N, B, H, W):\n",
        "  N_ = np.sqrt(N).round().astype(np.int32)\n",
        "  grid_y, grid_x = meshgrid2d(B, N_, N_, stack=False, device='cuda')\n",
        "  grid_y =  grid_y.reshape(B, -1)/float(N_-1) * (H-16)\n",
        "  grid_x =  grid_x.reshape(B, -1)/float(N_-1) * (W-16)\n",
        "\n",
        "  # normalise to values of range [-1, 1] - x = -1, y = -1 is the left-top pixel\n",
        "  grid_x = (grid_x - W) / W \n",
        "  grid_y = (grid_y - H) / H\n",
        "  xy = torch.stack([grid_x, grid_y], dim=-1) # B, N_*N_, 2\n",
        "  xy = xy.view(B, N_, N_, 2)\n",
        "\n",
        "  return xy"
      ],
      "metadata": {
        "id": "Y3-ulKDgaVfl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our prediction model"
      ],
      "metadata": {
        "id": "6bCCvwlYaTa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialise_model(device):\n",
        "  # Initialize model with the best available weights\n",
        "  # create an instance of (e.g.) torchvision.models.segmentation.fcn_resnet50\n",
        "  # and tell it to load pretrained weights\n",
        "  weights = FCN_ResNet50_Weights.DEFAULT\n",
        "  modified_model = fcn_resnet50(weights=weights)\n",
        "\n",
        "  # we are feature extracting so we only need to compute weights for the new layer\n",
        "  set_parameter_requires_grad(modified_model, True)\n",
        "\n",
        "  # modify that model by removing its final layer and replacing with a 2D vector output at each pixel(?) (instead of 20 class logits)\n",
        "  # instead of torch.Size([1, 21, 120, 240]) -> torch.Size([1, 2, 120, 240])\n",
        "  modified_model.classifier[3] = nn.Sequential()\n",
        "  modified_model.classifier[4] = nn.Conv2d(512, 2, kernel_size=(1, 1), stride=(1, 1))\n",
        "  # print(modified_model)\n",
        "\n",
        "  # model to train() and load onto computation devicce\n",
        "  modified_model.to(device)\n",
        "\n",
        "  return modified_model"
      ],
      "metadata": {
        "id": "fZta1fBFZJ9d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train function"
      ],
      "metadata": {
        "id": "cb1eFevUae33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define train function\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_aux=False):\n",
        "  model.to(device)\n",
        "  since = time.time()\n",
        "\n",
        "  val_loss_history = []\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            total_samples=0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for i_batch, sample_batched in enumerate(dataloaders[phase]):\n",
        "              batch_size = len(sample_batched['id'])\n",
        "              total_samples+=batch_size\n",
        "\n",
        "              inputs = sample_batched['image0']\n",
        "              coords = sample_batched['coords'] \n",
        "\n",
        "              inputs = inputs.to(device).float() #torch.Size([B, 3, 120, 240])\n",
        "              coords = coords.to(device) # torch.Size([B, 1, 4096, 2])\n",
        "              \n",
        "              # zero the parameter gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # forward\n",
        "              # track history if only in train\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs) # torch.Size([B, 2, H, W]) same as inputs shape\n",
        "                    outputs = outputs['out']\n",
        "\n",
        "                    # take the values of outputs from the NxN grid points\n",
        "                    grid = get_normalised_grid(coords.shape[2], batch_size, outputs.shape[2], outputs.shape[3]) # ([B, H(64), W(64), 2])\n",
        "                    outputs = torch.nn.functional.grid_sample(outputs, grid) # torch.size([B,2,H,W])\n",
        "\n",
        "                    # reshape to match coords shape\n",
        "                    outputs = torch.permute(outputs, (0, 2, 3, 1)) # torch.Size([B, H, W, 2])\n",
        "                    # outputs = outputs.view(batch_size,1,-1,2) # torch.Size([B, 1, 120*240, 2])\n",
        "                    coords = coords.view(batch_size, outputs.shape[1], outputs.shape[2], 2) # torch.Size([B, H, W, 2])\n",
        "\n",
        "                    loss = criterion(outputs, coords)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            if total_samples != 0:\n",
        "              epoch_loss = running_loss / total_samples\n",
        "              print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
        "\n",
        "            # deep copy the model\n",
        "            if epoch == 0:\n",
        "                best_loss = epoch_loss\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_loss_history.append(epoch_loss)\n",
        "\n",
        "            print()\n",
        "            \n",
        "        time_elapsed = time.time() - since\n",
        "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "        # print('Best val loss: {:4f}\\n'.format(best_loss))\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, val_loss_history\n"
      ],
      "metadata": {
        "id": "ItzqEpfDZWoJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Initializing Datasets and Dataloaders"
      ],
      "metadata": {
        "id": "jB0a8m5Ral92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "\n",
        "TRAIN_DATA = \"training_data2_2023-01-16\"\n",
        "!unzip -d \"$TRAIN_DATA\"/ /content/drive/MyDrive/\"$TRAIN_DATA\".zip # unziping training data\n",
        "\n",
        "dataset = TaiChiDataset(log_file=TRAIN_DATA+'/sample_ids.txt',\n",
        "                        root_dir=TRAIN_DATA,\n",
        "                        check=True,\n",
        "                        transform=ToTensor()\n",
        "                        )\n",
        "print(len(dataset))"
      ],
      "metadata": {
        "id": "fPDDjpIcb1ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "925aeb85-2baf-4bff-a742-aa7dd0025025"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/training_data2_2023-01-16.zip\n",
            "replace training_data2_2023-01-16/frame0/-CR4xjdQbkc_920.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, validation_split, batch_size, shuffle_dataset, random_seed):\n",
        "  dataset_size = len(dataset)\n",
        "  indices = list(range(dataset_size))\n",
        "  split = int(np.floor(validation_split * dataset_size))\n",
        "  if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "  train_indices, val_indices = indices[split:], indices[:split]\n",
        "  train_sampler = SubsetRandomSampler(train_indices)\n",
        "  valid_sampler = SubsetRandomSampler(val_indices)\n",
        "  \n",
        "  train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "  validation_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
        "\n",
        "  return train_loader, validation_loader"
      ],
      "metadata": {
        "id": "RP7650LcaoNf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & evaluating the model"
      ],
      "metadata": {
        "id": "B_XIRuWYaotC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set computation device\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# initialise model\n",
        "modified_model = initialise_model(device)\n",
        "\n",
        "# see what parameters will be tuned\n",
        "params_to_update = modified_model.parameters()\n",
        "print('Params to learn:')\n",
        "for name, param in modified_model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "      print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGH5fqrGkFhj",
        "outputId": "ee4a0503-5fba-42cb-e760-8db987f6191e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params to learn:\n",
            "classifier.4.weight\n",
            "classifier.4.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "validation_split = .0\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "batch_size = len(dataset)\n",
        "num_epochs = 400\n",
        "\n",
        "# Get train and validation dataloaders\n",
        "train_loader, validation_loader = split_dataset(dataset, validation_split, batch_size, shuffle_dataset, random_seed)\n",
        "dataloaders_dict = {'train': train_loader, 'val': validation_loader}\n",
        "\n",
        "# Define optimizer\n",
        "my_optimizer = optim.SGD(params_to_update, lr=0.1, momentum=0.9)\n",
        "\n",
        "# Setup the loss\n",
        "my_criterion = nn.MSELoss()\n",
        "\n",
        "# Train and evaluate\n",
        "modified_model, hist = train_model(modified_model,\n",
        "                                   dataloaders_dict,\n",
        "                                   my_criterion,\n",
        "                                   my_optimizer,\n",
        "                                   num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "Cp-DDzyHaqvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee62f159-b8b5-4c5c-a8e9-a122cdca5de6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "Epoch 0/399\n",
            "----------\n",
            "train Loss: 88252.6406\n",
            "\n",
            "\n",
            "Training complete in 0m 0s\n",
            "----------\n",
            "Epoch 1/399\n",
            "----------\n",
            "train Loss: 198899.3906\n",
            "\n",
            "\n",
            "Training complete in 0m 0s\n",
            "----------\n",
            "Epoch 2/399\n",
            "----------\n",
            "train Loss: 26299.6016\n",
            "\n",
            "\n",
            "Training complete in 0m 1s\n",
            "----------\n",
            "Epoch 3/399\n",
            "----------\n",
            "train Loss: 91878.7500\n",
            "\n",
            "\n",
            "Training complete in 0m 1s\n",
            "----------\n",
            "Epoch 4/399\n",
            "----------\n",
            "train Loss: 128475.6953\n",
            "\n",
            "\n",
            "Training complete in 0m 1s\n",
            "----------\n",
            "Epoch 5/399\n",
            "----------\n",
            "train Loss: 12897.6641\n",
            "\n",
            "\n",
            "Training complete in 0m 1s\n",
            "----------\n",
            "Epoch 6/399\n",
            "----------\n",
            "train Loss: 92849.4766\n",
            "\n",
            "\n",
            "Training complete in 0m 2s\n",
            "----------\n",
            "Epoch 7/399\n",
            "----------\n",
            "train Loss: 70710.1172\n",
            "\n",
            "\n",
            "Training complete in 0m 2s\n",
            "----------\n",
            "Epoch 8/399\n",
            "----------\n",
            "train Loss: 11056.5303\n",
            "\n",
            "\n",
            "Training complete in 0m 2s\n",
            "----------\n",
            "Epoch 9/399\n",
            "----------\n",
            "train Loss: 83539.7891\n",
            "\n",
            "\n",
            "Training complete in 0m 2s\n",
            "----------\n",
            "Epoch 10/399\n",
            "----------\n",
            "train Loss: 37742.8398\n",
            "\n",
            "\n",
            "Training complete in 0m 2s\n",
            "----------\n",
            "Epoch 11/399\n",
            "----------\n",
            "train Loss: 18053.0254\n",
            "\n",
            "\n",
            "Training complete in 0m 3s\n",
            "----------\n",
            "Epoch 12/399\n",
            "----------\n",
            "train Loss: 63433.1328\n",
            "\n",
            "\n",
            "Training complete in 0m 3s\n",
            "----------\n",
            "Epoch 13/399\n",
            "----------\n",
            "train Loss: 15802.5283\n",
            "\n",
            "\n",
            "Training complete in 0m 3s\n",
            "----------\n",
            "Epoch 14/399\n",
            "----------\n",
            "train Loss: 24620.2773\n",
            "\n",
            "\n",
            "Training complete in 0m 3s\n",
            "----------\n",
            "Epoch 15/399\n",
            "----------\n",
            "train Loss: 44790.8789\n",
            "\n",
            "\n",
            "Training complete in 0m 4s\n",
            "----------\n",
            "Epoch 16/399\n",
            "----------\n",
            "train Loss: 5539.6235\n",
            "\n",
            "\n",
            "Training complete in 0m 4s\n",
            "----------\n",
            "Epoch 17/399\n",
            "----------\n",
            "train Loss: 25816.0391\n",
            "\n",
            "\n",
            "Training complete in 0m 4s\n",
            "----------\n",
            "Epoch 18/399\n",
            "----------\n",
            "train Loss: 28700.2734\n",
            "\n",
            "\n",
            "Training complete in 0m 4s\n",
            "----------\n",
            "Epoch 19/399\n",
            "----------\n",
            "train Loss: 4802.6924\n",
            "\n",
            "\n",
            "Training complete in 0m 4s\n",
            "----------\n",
            "Epoch 20/399\n",
            "----------\n",
            "train Loss: 25025.8867\n",
            "\n",
            "\n",
            "Training complete in 0m 5s\n",
            "----------\n",
            "Epoch 21/399\n",
            "----------\n",
            "train Loss: 15521.1055\n",
            "\n",
            "\n",
            "Training complete in 0m 5s\n",
            "----------\n",
            "Epoch 22/399\n",
            "----------\n",
            "train Loss: 4737.5044\n",
            "\n",
            "\n",
            "Training complete in 0m 5s\n",
            "----------\n",
            "Epoch 23/399\n",
            "----------\n",
            "train Loss: 21195.5625\n",
            "\n",
            "\n",
            "Training complete in 0m 5s\n",
            "----------\n",
            "Epoch 24/399\n",
            "----------\n",
            "train Loss: 8601.8691\n",
            "\n",
            "\n",
            "Training complete in 0m 5s\n",
            "----------\n",
            "Epoch 25/399\n",
            "----------\n",
            "train Loss: 6754.8901\n",
            "\n",
            "\n",
            "Training complete in 0m 6s\n",
            "----------\n",
            "Epoch 26/399\n",
            "----------\n",
            "train Loss: 15564.1963\n",
            "\n",
            "\n",
            "Training complete in 0m 6s\n",
            "----------\n",
            "Epoch 27/399\n",
            "----------\n",
            "train Loss: 3887.7686\n",
            "\n",
            "\n",
            "Training complete in 0m 6s\n",
            "----------\n",
            "Epoch 28/399\n",
            "----------\n",
            "train Loss: 8057.0464\n",
            "\n",
            "\n",
            "Training complete in 0m 6s\n",
            "----------\n",
            "Epoch 29/399\n",
            "----------\n",
            "train Loss: 11330.9902\n",
            "\n",
            "\n",
            "Training complete in 0m 6s\n",
            "----------\n",
            "Epoch 30/399\n",
            "----------\n",
            "train Loss: 2558.2107\n",
            "\n",
            "\n",
            "Training complete in 0m 7s\n",
            "----------\n",
            "Epoch 31/399\n",
            "----------\n",
            "train Loss: 7907.4302\n",
            "\n",
            "\n",
            "Training complete in 0m 7s\n",
            "----------\n",
            "Epoch 32/399\n",
            "----------\n",
            "train Loss: 7064.6997\n",
            "\n",
            "\n",
            "Training complete in 0m 7s\n",
            "----------\n",
            "Epoch 33/399\n",
            "----------\n",
            "train Loss: 2382.3123\n",
            "\n",
            "\n",
            "Training complete in 0m 7s\n",
            "----------\n",
            "Epoch 34/399\n",
            "----------\n",
            "train Loss: 7380.7964\n",
            "\n",
            "\n",
            "Training complete in 0m 8s\n",
            "----------\n",
            "Epoch 35/399\n",
            "----------\n",
            "train Loss: 4341.5435\n",
            "\n",
            "\n",
            "Training complete in 0m 8s\n",
            "----------\n",
            "Epoch 36/399\n",
            "----------\n",
            "train Loss: 2575.0063\n",
            "\n",
            "\n",
            "Training complete in 0m 8s\n",
            "----------\n",
            "Epoch 37/399\n",
            "----------\n",
            "train Loss: 6084.8535\n",
            "\n",
            "\n",
            "Training complete in 0m 8s\n",
            "----------\n",
            "Epoch 38/399\n",
            "----------\n",
            "train Loss: 2839.8201\n",
            "\n",
            "\n",
            "Training complete in 0m 8s\n",
            "----------\n",
            "Epoch 39/399\n",
            "----------\n",
            "train Loss: 3117.7754\n",
            "\n",
            "\n",
            "Training complete in 0m 9s\n",
            "----------\n",
            "Epoch 40/399\n",
            "----------\n",
            "train Loss: 4730.0479\n",
            "\n",
            "\n",
            "Training complete in 0m 9s\n",
            "----------\n",
            "Epoch 41/399\n",
            "----------\n",
            "train Loss: 1921.6309\n",
            "\n",
            "\n",
            "Training complete in 0m 9s\n",
            "----------\n",
            "Epoch 42/399\n",
            "----------\n",
            "train Loss: 3218.8096\n",
            "\n",
            "\n",
            "Training complete in 0m 9s\n",
            "----------\n",
            "Epoch 43/399\n",
            "----------\n",
            "train Loss: 3569.0581\n",
            "\n",
            "\n",
            "Training complete in 0m 9s\n",
            "----------\n",
            "Epoch 44/399\n",
            "----------\n",
            "train Loss: 1705.0472\n",
            "\n",
            "\n",
            "Training complete in 0m 10s\n",
            "----------\n",
            "Epoch 45/399\n",
            "----------\n",
            "train Loss: 3088.8425\n",
            "\n",
            "\n",
            "Training complete in 0m 10s\n",
            "----------\n",
            "Epoch 46/399\n",
            "----------\n",
            "train Loss: 2579.5227\n",
            "\n",
            "\n",
            "Training complete in 0m 10s\n",
            "----------\n",
            "Epoch 47/399\n",
            "----------\n",
            "train Loss: 1716.0852\n",
            "\n",
            "\n",
            "Training complete in 0m 10s\n",
            "----------\n",
            "Epoch 48/399\n",
            "----------\n",
            "train Loss: 2878.8137\n",
            "\n",
            "\n",
            "Training complete in 0m 10s\n",
            "----------\n",
            "Epoch 49/399\n",
            "----------\n",
            "train Loss: 2004.0532\n",
            "\n",
            "\n",
            "Training complete in 0m 11s\n",
            "----------\n",
            "Epoch 50/399\n",
            "----------\n",
            "train Loss: 1772.7439\n",
            "\n",
            "\n",
            "Training complete in 0m 11s\n",
            "----------\n",
            "Epoch 51/399\n",
            "----------\n",
            "train Loss: 2477.0137\n",
            "\n",
            "\n",
            "Training complete in 0m 11s\n",
            "----------\n",
            "Epoch 52/399\n",
            "----------\n",
            "train Loss: 1667.4261\n",
            "\n",
            "\n",
            "Training complete in 0m 11s\n",
            "----------\n",
            "Epoch 53/399\n",
            "----------\n",
            "train Loss: 1877.2930\n",
            "\n",
            "\n",
            "Training complete in 0m 12s\n",
            "----------\n",
            "Epoch 54/399\n",
            "----------\n",
            "train Loss: 2132.4062\n",
            "\n",
            "\n",
            "Training complete in 0m 12s\n",
            "----------\n",
            "Epoch 55/399\n",
            "----------\n",
            "train Loss: 1480.1868\n",
            "\n",
            "\n",
            "Training complete in 0m 12s\n",
            "----------\n",
            "Epoch 56/399\n",
            "----------\n",
            "train Loss: 1842.8213\n",
            "\n",
            "\n",
            "Training complete in 0m 12s\n",
            "----------\n",
            "Epoch 57/399\n",
            "----------\n",
            "train Loss: 1830.5209\n",
            "\n",
            "\n",
            "Training complete in 0m 12s\n",
            "----------\n",
            "Epoch 58/399\n",
            "----------\n",
            "train Loss: 1454.6752\n",
            "\n",
            "\n",
            "Training complete in 0m 13s\n",
            "----------\n",
            "Epoch 59/399\n",
            "----------\n",
            "train Loss: 1789.6597\n",
            "\n",
            "\n",
            "Training complete in 0m 13s\n",
            "----------\n",
            "Epoch 60/399\n",
            "----------\n",
            "train Loss: 1592.9673\n",
            "\n",
            "\n",
            "Training complete in 0m 13s\n",
            "----------\n",
            "Epoch 61/399\n",
            "----------\n",
            "train Loss: 1439.1508\n",
            "\n",
            "\n",
            "Training complete in 0m 13s\n",
            "----------\n",
            "Epoch 62/399\n",
            "----------\n",
            "train Loss: 1694.8000\n",
            "\n",
            "\n",
            "Training complete in 0m 13s\n",
            "----------\n",
            "Epoch 63/399\n",
            "----------\n",
            "train Loss: 1462.7891\n",
            "\n",
            "\n",
            "Training complete in 0m 14s\n",
            "----------\n",
            "Epoch 64/399\n",
            "----------\n",
            "train Loss: 1450.4384\n",
            "\n",
            "\n",
            "Training complete in 0m 14s\n",
            "----------\n",
            "Epoch 65/399\n",
            "----------\n",
            "train Loss: 1575.3394\n",
            "\n",
            "\n",
            "Training complete in 0m 14s\n",
            "----------\n",
            "Epoch 66/399\n",
            "----------\n",
            "train Loss: 1372.8479\n",
            "\n",
            "\n",
            "Training complete in 0m 14s\n",
            "----------\n",
            "Epoch 67/399\n",
            "----------\n",
            "train Loss: 1447.6112\n",
            "\n",
            "\n",
            "Training complete in 0m 15s\n",
            "----------\n",
            "Epoch 68/399\n",
            "----------\n",
            "train Loss: 1478.0236\n",
            "\n",
            "\n",
            "Training complete in 0m 15s\n",
            "----------\n",
            "Epoch 69/399\n",
            "----------\n",
            "train Loss: 1333.1497\n",
            "\n",
            "\n",
            "Training complete in 0m 15s\n",
            "----------\n",
            "Epoch 70/399\n",
            "----------\n",
            "train Loss: 1424.6752\n",
            "\n",
            "\n",
            "Training complete in 0m 15s\n",
            "----------\n",
            "Epoch 71/399\n",
            "----------\n",
            "train Loss: 1394.6569\n",
            "\n",
            "\n",
            "Training complete in 0m 15s\n",
            "----------\n",
            "Epoch 72/399\n",
            "----------\n",
            "train Loss: 1318.3101\n",
            "\n",
            "\n",
            "Training complete in 0m 16s\n",
            "----------\n",
            "Epoch 73/399\n",
            "----------\n",
            "train Loss: 1393.4402\n",
            "\n",
            "\n",
            "Training complete in 0m 16s\n",
            "----------\n",
            "Epoch 74/399\n",
            "----------\n",
            "train Loss: 1330.3914\n",
            "\n",
            "\n",
            "Training complete in 0m 16s\n",
            "----------\n",
            "Epoch 75/399\n",
            "----------\n",
            "train Loss: 1304.1470\n",
            "\n",
            "\n",
            "Training complete in 0m 16s\n",
            "----------\n",
            "Epoch 76/399\n",
            "----------\n",
            "train Loss: 1354.2584\n",
            "\n",
            "\n",
            "Training complete in 0m 16s\n",
            "----------\n",
            "Epoch 77/399\n",
            "----------\n",
            "train Loss: 1292.3281\n",
            "\n",
            "\n",
            "Training complete in 0m 17s\n",
            "----------\n",
            "Epoch 78/399\n",
            "----------\n",
            "train Loss: 1296.2094\n",
            "\n",
            "\n",
            "Training complete in 0m 17s\n",
            "----------\n",
            "Epoch 79/399\n",
            "----------\n",
            "train Loss: 1313.4514\n",
            "\n",
            "\n",
            "Training complete in 0m 17s\n",
            "----------\n",
            "Epoch 80/399\n",
            "----------\n",
            "train Loss: 1263.1550\n",
            "\n",
            "\n",
            "Training complete in 0m 17s\n",
            "----------\n",
            "Epoch 81/399\n",
            "----------\n",
            "train Loss: 1283.4498\n",
            "\n",
            "\n",
            "Training complete in 0m 18s\n",
            "----------\n",
            "Epoch 82/399\n",
            "----------\n",
            "train Loss: 1281.0162\n",
            "\n",
            "\n",
            "Training complete in 0m 18s\n",
            "----------\n",
            "Epoch 83/399\n",
            "----------\n",
            "train Loss: 1247.0870\n",
            "\n",
            "\n",
            "Training complete in 0m 18s\n",
            "----------\n",
            "Epoch 84/399\n",
            "----------\n",
            "train Loss: 1266.0081\n",
            "\n",
            "\n",
            "Training complete in 0m 18s\n",
            "----------\n",
            "Epoch 85/399\n",
            "----------\n",
            "train Loss: 1250.4677\n",
            "\n",
            "\n",
            "Training complete in 0m 18s\n",
            "----------\n",
            "Epoch 86/399\n",
            "----------\n",
            "train Loss: 1233.8596\n",
            "\n",
            "\n",
            "Training complete in 0m 19s\n",
            "----------\n",
            "Epoch 87/399\n",
            "----------\n",
            "train Loss: 1248.3527\n",
            "\n",
            "\n",
            "Training complete in 0m 19s\n",
            "----------\n",
            "Epoch 88/399\n",
            "----------\n",
            "train Loss: 1228.4623\n",
            "\n",
            "\n",
            "Training complete in 0m 19s\n",
            "----------\n",
            "Epoch 89/399\n",
            "----------\n",
            "train Loss: 1222.3635\n",
            "\n",
            "\n",
            "Training complete in 0m 19s\n",
            "----------\n",
            "Epoch 90/399\n",
            "----------\n",
            "train Loss: 1228.9619\n",
            "\n",
            "\n",
            "Training complete in 0m 19s\n",
            "----------\n",
            "Epoch 91/399\n",
            "----------\n",
            "train Loss: 1211.1971\n",
            "\n",
            "\n",
            "Training complete in 0m 20s\n",
            "----------\n",
            "Epoch 92/399\n",
            "----------\n",
            "train Loss: 1211.8444\n",
            "\n",
            "\n",
            "Training complete in 0m 20s\n",
            "----------\n",
            "Epoch 93/399\n",
            "----------\n",
            "train Loss: 1211.2689\n",
            "\n",
            "\n",
            "Training complete in 0m 20s\n",
            "----------\n",
            "Epoch 94/399\n",
            "----------\n",
            "train Loss: 1197.1901\n",
            "\n",
            "\n",
            "Training complete in 0m 20s\n",
            "----------\n",
            "Epoch 95/399\n",
            "----------\n",
            "train Loss: 1200.0538\n",
            "\n",
            "\n",
            "Training complete in 0m 21s\n",
            "----------\n",
            "Epoch 96/399\n",
            "----------\n",
            "train Loss: 1195.2184\n",
            "\n",
            "\n",
            "Training complete in 0m 21s\n",
            "----------\n",
            "Epoch 97/399\n",
            "----------\n",
            "train Loss: 1185.7820\n",
            "\n",
            "\n",
            "Training complete in 0m 21s\n",
            "----------\n",
            "Epoch 98/399\n",
            "----------\n",
            "train Loss: 1187.8538\n",
            "\n",
            "\n",
            "Training complete in 0m 21s\n",
            "----------\n",
            "Epoch 99/399\n",
            "----------\n",
            "train Loss: 1180.7563\n",
            "\n",
            "\n",
            "Training complete in 0m 21s\n",
            "----------\n",
            "Epoch 100/399\n",
            "----------\n",
            "train Loss: 1175.4451\n",
            "\n",
            "\n",
            "Training complete in 0m 22s\n",
            "----------\n",
            "Epoch 101/399\n",
            "----------\n",
            "train Loss: 1176.1238\n",
            "\n",
            "\n",
            "Training complete in 0m 22s\n",
            "----------\n",
            "Epoch 102/399\n",
            "----------\n",
            "train Loss: 1168.7050\n",
            "\n",
            "\n",
            "Training complete in 0m 22s\n",
            "----------\n",
            "Epoch 103/399\n",
            "----------\n",
            "train Loss: 1165.6300\n",
            "\n",
            "\n",
            "Training complete in 0m 22s\n",
            "----------\n",
            "Epoch 104/399\n",
            "----------\n",
            "train Loss: 1164.2861\n",
            "\n",
            "\n",
            "Training complete in 0m 23s\n",
            "----------\n",
            "Epoch 105/399\n",
            "----------\n",
            "train Loss: 1157.8663\n",
            "\n",
            "\n",
            "Training complete in 0m 23s\n",
            "----------\n",
            "Epoch 106/399\n",
            "----------\n",
            "train Loss: 1156.2601\n",
            "\n",
            "\n",
            "Training complete in 0m 23s\n",
            "----------\n",
            "Epoch 107/399\n",
            "----------\n",
            "train Loss: 1153.4358\n",
            "\n",
            "\n",
            "Training complete in 0m 23s\n",
            "----------\n",
            "Epoch 108/399\n",
            "----------\n",
            "train Loss: 1148.1332\n",
            "\n",
            "\n",
            "Training complete in 0m 23s\n",
            "----------\n",
            "Epoch 109/399\n",
            "----------\n",
            "train Loss: 1146.7854\n",
            "\n",
            "\n",
            "Training complete in 0m 24s\n",
            "----------\n",
            "Epoch 110/399\n",
            "----------\n",
            "train Loss: 1143.2236\n",
            "\n",
            "\n",
            "Training complete in 0m 24s\n",
            "----------\n",
            "Epoch 111/399\n",
            "----------\n",
            "train Loss: 1139.2672\n",
            "\n",
            "\n",
            "Training complete in 0m 24s\n",
            "----------\n",
            "Epoch 112/399\n",
            "----------\n",
            "train Loss: 1137.6981\n",
            "\n",
            "\n",
            "Training complete in 0m 24s\n",
            "----------\n",
            "Epoch 113/399\n",
            "----------\n",
            "train Loss: 1133.7997\n",
            "\n",
            "\n",
            "Training complete in 0m 25s\n",
            "----------\n",
            "Epoch 114/399\n",
            "----------\n",
            "train Loss: 1130.7683\n",
            "\n",
            "\n",
            "Training complete in 0m 25s\n",
            "----------\n",
            "Epoch 115/399\n",
            "----------\n",
            "train Loss: 1128.8459\n",
            "\n",
            "\n",
            "Training complete in 0m 25s\n",
            "----------\n",
            "Epoch 116/399\n",
            "----------\n",
            "train Loss: 1125.1431\n",
            "\n",
            "\n",
            "Training complete in 0m 25s\n",
            "----------\n",
            "Epoch 117/399\n",
            "----------\n",
            "train Loss: 1122.6906\n",
            "\n",
            "\n",
            "Training complete in 0m 25s\n",
            "----------\n",
            "Epoch 118/399\n",
            "----------\n",
            "train Loss: 1120.3455\n",
            "\n",
            "\n",
            "Training complete in 0m 26s\n",
            "----------\n",
            "Epoch 119/399\n",
            "----------\n",
            "train Loss: 1116.9983\n",
            "\n",
            "\n",
            "Training complete in 0m 26s\n",
            "----------\n",
            "Epoch 120/399\n",
            "----------\n",
            "train Loss: 1114.8699\n",
            "\n",
            "\n",
            "Training complete in 0m 26s\n",
            "----------\n",
            "Epoch 121/399\n",
            "----------\n",
            "train Loss: 1112.2970\n",
            "\n",
            "\n",
            "Training complete in 0m 26s\n",
            "----------\n",
            "Epoch 122/399\n",
            "----------\n",
            "train Loss: 1109.3417\n",
            "\n",
            "\n",
            "Training complete in 0m 27s\n",
            "----------\n",
            "Epoch 123/399\n",
            "----------\n",
            "train Loss: 1107.2794\n",
            "\n",
            "\n",
            "Training complete in 0m 27s\n",
            "----------\n",
            "Epoch 124/399\n",
            "----------\n",
            "train Loss: 1104.6285\n",
            "\n",
            "\n",
            "Training complete in 0m 27s\n",
            "----------\n",
            "Epoch 125/399\n",
            "----------\n",
            "train Loss: 1102.0590\n",
            "\n",
            "\n",
            "Training complete in 0m 27s\n",
            "----------\n",
            "Epoch 126/399\n",
            "----------\n",
            "train Loss: 1099.9812\n",
            "\n",
            "\n",
            "Training complete in 0m 27s\n",
            "----------\n",
            "Epoch 127/399\n",
            "----------\n",
            "train Loss: 1097.3628\n",
            "\n",
            "\n",
            "Training complete in 0m 28s\n",
            "----------\n",
            "Epoch 128/399\n",
            "----------\n",
            "train Loss: 1095.0510\n",
            "\n",
            "\n",
            "Training complete in 0m 28s\n",
            "----------\n",
            "Epoch 129/399\n",
            "----------\n",
            "train Loss: 1092.9373\n",
            "\n",
            "\n",
            "Training complete in 0m 28s\n",
            "----------\n",
            "Epoch 130/399\n",
            "----------\n",
            "train Loss: 1090.4585\n",
            "\n",
            "\n",
            "Training complete in 0m 28s\n",
            "----------\n",
            "Epoch 131/399\n",
            "----------\n",
            "train Loss: 1088.3300\n",
            "\n",
            "\n",
            "Training complete in 0m 29s\n",
            "----------\n",
            "Epoch 132/399\n",
            "----------\n",
            "train Loss: 1086.1730\n",
            "\n",
            "\n",
            "Training complete in 0m 29s\n",
            "----------\n",
            "Epoch 133/399\n",
            "----------\n",
            "train Loss: 1083.8466\n",
            "\n",
            "\n",
            "Training complete in 0m 29s\n",
            "----------\n",
            "Epoch 134/399\n",
            "----------\n",
            "train Loss: 1081.8323\n",
            "\n",
            "\n",
            "Training complete in 0m 29s\n",
            "----------\n",
            "Epoch 135/399\n",
            "----------\n",
            "train Loss: 1079.6913\n",
            "\n",
            "\n",
            "Training complete in 0m 29s\n",
            "----------\n",
            "Epoch 136/399\n",
            "----------\n",
            "train Loss: 1077.5226\n",
            "\n",
            "\n",
            "Training complete in 0m 30s\n",
            "----------\n",
            "Epoch 137/399\n",
            "----------\n",
            "train Loss: 1075.5603\n",
            "\n",
            "\n",
            "Training complete in 0m 30s\n",
            "----------\n",
            "Epoch 138/399\n",
            "----------\n",
            "train Loss: 1073.4612\n",
            "\n",
            "\n",
            "Training complete in 0m 30s\n",
            "----------\n",
            "Epoch 139/399\n",
            "----------\n",
            "train Loss: 1071.4343\n",
            "\n",
            "\n",
            "Training complete in 0m 30s\n",
            "----------\n",
            "Epoch 140/399\n",
            "----------\n",
            "train Loss: 1069.5150\n",
            "\n",
            "\n",
            "Training complete in 0m 31s\n",
            "----------\n",
            "Epoch 141/399\n",
            "----------\n",
            "train Loss: 1067.4872\n",
            "\n",
            "\n",
            "Training complete in 0m 31s\n",
            "----------\n",
            "Epoch 142/399\n",
            "----------\n",
            "train Loss: 1065.5637\n",
            "\n",
            "\n",
            "Training complete in 0m 31s\n",
            "----------\n",
            "Epoch 143/399\n",
            "----------\n",
            "train Loss: 1063.6797\n",
            "\n",
            "\n",
            "Training complete in 0m 31s\n",
            "----------\n",
            "Epoch 144/399\n",
            "----------\n",
            "train Loss: 1061.7363\n",
            "\n",
            "\n",
            "Training complete in 0m 31s\n",
            "----------\n",
            "Epoch 145/399\n",
            "----------\n",
            "train Loss: 1059.8979\n",
            "\n",
            "\n",
            "Training complete in 0m 32s\n",
            "----------\n",
            "Epoch 146/399\n",
            "----------\n",
            "train Loss: 1058.0514\n",
            "\n",
            "\n",
            "Training complete in 0m 32s\n",
            "----------\n",
            "Epoch 147/399\n",
            "----------\n",
            "train Loss: 1056.1935\n",
            "\n",
            "\n",
            "Training complete in 0m 32s\n",
            "----------\n",
            "Epoch 148/399\n",
            "----------\n",
            "train Loss: 1054.4208\n",
            "\n",
            "\n",
            "Training complete in 0m 32s\n",
            "----------\n",
            "Epoch 149/399\n",
            "----------\n",
            "train Loss: 1052.6237\n",
            "\n",
            "\n",
            "Training complete in 0m 33s\n",
            "----------\n",
            "Epoch 150/399\n",
            "----------\n",
            "train Loss: 1050.8472\n",
            "\n",
            "\n",
            "Training complete in 0m 33s\n",
            "----------\n",
            "Epoch 151/399\n",
            "----------\n",
            "train Loss: 1049.1240\n",
            "\n",
            "\n",
            "Training complete in 0m 33s\n",
            "----------\n",
            "Epoch 152/399\n",
            "----------\n",
            "train Loss: 1047.3815\n",
            "\n",
            "\n",
            "Training complete in 0m 33s\n",
            "----------\n",
            "Epoch 153/399\n",
            "----------\n",
            "train Loss: 1045.6776\n",
            "\n",
            "\n",
            "Training complete in 0m 33s\n",
            "----------\n",
            "Epoch 154/399\n",
            "----------\n",
            "train Loss: 1044.0063\n",
            "\n",
            "\n",
            "Training complete in 0m 34s\n",
            "----------\n",
            "Epoch 155/399\n",
            "----------\n",
            "train Loss: 1042.3225\n",
            "\n",
            "\n",
            "Training complete in 0m 34s\n",
            "----------\n",
            "Epoch 156/399\n",
            "----------\n",
            "train Loss: 1040.6792\n",
            "\n",
            "\n",
            "Training complete in 0m 34s\n",
            "----------\n",
            "Epoch 157/399\n",
            "----------\n",
            "train Loss: 1039.0521\n",
            "\n",
            "\n",
            "Training complete in 0m 34s\n",
            "----------\n",
            "Epoch 158/399\n",
            "----------\n",
            "train Loss: 1037.4277\n",
            "\n",
            "\n",
            "Training complete in 0m 35s\n",
            "----------\n",
            "Epoch 159/399\n",
            "----------\n",
            "train Loss: 1035.8395\n",
            "\n",
            "\n",
            "Training complete in 0m 35s\n",
            "----------\n",
            "Epoch 160/399\n",
            "----------\n",
            "train Loss: 1034.2593\n",
            "\n",
            "\n",
            "Training complete in 0m 35s\n",
            "----------\n",
            "Epoch 161/399\n",
            "----------\n",
            "train Loss: 1032.6906\n",
            "\n",
            "\n",
            "Training complete in 0m 35s\n",
            "----------\n",
            "Epoch 162/399\n",
            "----------\n",
            "train Loss: 1031.1510\n",
            "\n",
            "\n",
            "Training complete in 0m 35s\n",
            "----------\n",
            "Epoch 163/399\n",
            "----------\n",
            "train Loss: 1029.6174\n",
            "\n",
            "\n",
            "Training complete in 0m 36s\n",
            "----------\n",
            "Epoch 164/399\n",
            "----------\n",
            "train Loss: 1028.1018\n",
            "\n",
            "\n",
            "Training complete in 0m 36s\n",
            "----------\n",
            "Epoch 165/399\n",
            "----------\n",
            "train Loss: 1026.6093\n",
            "\n",
            "\n",
            "Training complete in 0m 36s\n",
            "----------\n",
            "Epoch 166/399\n",
            "----------\n",
            "train Loss: 1025.1211\n",
            "\n",
            "\n",
            "Training complete in 0m 36s\n",
            "----------\n",
            "Epoch 167/399\n",
            "----------\n",
            "train Loss: 1023.6539\n",
            "\n",
            "\n",
            "Training complete in 0m 37s\n",
            "----------\n",
            "Epoch 168/399\n",
            "----------\n",
            "train Loss: 1022.2024\n",
            "\n",
            "\n",
            "Training complete in 0m 37s\n",
            "----------\n",
            "Epoch 169/399\n",
            "----------\n",
            "train Loss: 1020.7623\n",
            "\n",
            "\n",
            "Training complete in 0m 37s\n",
            "----------\n",
            "Epoch 170/399\n",
            "----------\n",
            "train Loss: 1019.3396\n",
            "\n",
            "\n",
            "Training complete in 0m 37s\n",
            "----------\n",
            "Epoch 171/399\n",
            "----------\n",
            "train Loss: 1017.9315\n",
            "\n",
            "\n",
            "Training complete in 0m 37s\n",
            "----------\n",
            "Epoch 172/399\n",
            "----------\n",
            "train Loss: 1016.5364\n",
            "\n",
            "\n",
            "Training complete in 0m 38s\n",
            "----------\n",
            "Epoch 173/399\n",
            "----------\n",
            "train Loss: 1015.1561\n",
            "\n",
            "\n",
            "Training complete in 0m 38s\n",
            "----------\n",
            "Epoch 174/399\n",
            "----------\n",
            "train Loss: 1013.7870\n",
            "\n",
            "\n",
            "Training complete in 0m 38s\n",
            "----------\n",
            "Epoch 175/399\n",
            "----------\n",
            "train Loss: 1012.4321\n",
            "\n",
            "\n",
            "Training complete in 0m 38s\n",
            "----------\n",
            "Epoch 176/399\n",
            "----------\n",
            "train Loss: 1011.0921\n",
            "\n",
            "\n",
            "Training complete in 0m 39s\n",
            "----------\n",
            "Epoch 177/399\n",
            "----------\n",
            "train Loss: 1009.7636\n",
            "\n",
            "\n",
            "Training complete in 0m 39s\n",
            "----------\n",
            "Epoch 178/399\n",
            "----------\n",
            "train Loss: 1008.4481\n",
            "\n",
            "\n",
            "Training complete in 0m 39s\n",
            "----------\n",
            "Epoch 179/399\n",
            "----------\n",
            "train Loss: 1007.1459\n",
            "\n",
            "\n",
            "Training complete in 0m 39s\n",
            "----------\n",
            "Epoch 180/399\n",
            "----------\n",
            "train Loss: 1005.8536\n",
            "\n",
            "\n",
            "Training complete in 0m 39s\n",
            "----------\n",
            "Epoch 181/399\n",
            "----------\n",
            "train Loss: 1004.5756\n",
            "\n",
            "\n",
            "Training complete in 0m 40s\n",
            "----------\n",
            "Epoch 182/399\n",
            "----------\n",
            "train Loss: 1003.3094\n",
            "\n",
            "\n",
            "Training complete in 0m 40s\n",
            "----------\n",
            "Epoch 183/399\n",
            "----------\n",
            "train Loss: 1002.0564\n",
            "\n",
            "\n",
            "Training complete in 0m 40s\n",
            "----------\n",
            "Epoch 184/399\n",
            "----------\n",
            "train Loss: 1000.8129\n",
            "\n",
            "\n",
            "Training complete in 0m 40s\n",
            "----------\n",
            "Epoch 185/399\n",
            "----------\n",
            "train Loss: 999.5820\n",
            "\n",
            "\n",
            "Training complete in 0m 40s\n",
            "----------\n",
            "Epoch 186/399\n",
            "----------\n",
            "train Loss: 998.3616\n",
            "\n",
            "\n",
            "Training complete in 0m 41s\n",
            "----------\n",
            "Epoch 187/399\n",
            "----------\n",
            "train Loss: 997.1539\n",
            "\n",
            "\n",
            "Training complete in 0m 41s\n",
            "----------\n",
            "Epoch 188/399\n",
            "----------\n",
            "train Loss: 995.9550\n",
            "\n",
            "\n",
            "Training complete in 0m 41s\n",
            "----------\n",
            "Epoch 189/399\n",
            "----------\n",
            "train Loss: 994.7701\n",
            "\n",
            "\n",
            "Training complete in 0m 41s\n",
            "----------\n",
            "Epoch 190/399\n",
            "----------\n",
            "train Loss: 993.5964\n",
            "\n",
            "\n",
            "Training complete in 0m 42s\n",
            "----------\n",
            "Epoch 191/399\n",
            "----------\n",
            "train Loss: 992.4301\n",
            "\n",
            "\n",
            "Training complete in 0m 42s\n",
            "----------\n",
            "Epoch 192/399\n",
            "----------\n",
            "train Loss: 991.2751\n",
            "\n",
            "\n",
            "Training complete in 0m 42s\n",
            "----------\n",
            "Epoch 193/399\n",
            "----------\n",
            "train Loss: 990.1313\n",
            "\n",
            "\n",
            "Training complete in 0m 42s\n",
            "----------\n",
            "Epoch 194/399\n",
            "----------\n",
            "train Loss: 988.9966\n",
            "\n",
            "\n",
            "Training complete in 0m 42s\n",
            "----------\n",
            "Epoch 195/399\n",
            "----------\n",
            "train Loss: 987.8727\n",
            "\n",
            "\n",
            "Training complete in 0m 43s\n",
            "----------\n",
            "Epoch 196/399\n",
            "----------\n",
            "train Loss: 986.7582\n",
            "\n",
            "\n",
            "Training complete in 0m 43s\n",
            "----------\n",
            "Epoch 197/399\n",
            "----------\n",
            "train Loss: 985.6548\n",
            "\n",
            "\n",
            "Training complete in 0m 43s\n",
            "----------\n",
            "Epoch 198/399\n",
            "----------\n",
            "train Loss: 984.5603\n",
            "\n",
            "\n",
            "Training complete in 0m 43s\n",
            "----------\n",
            "Epoch 199/399\n",
            "----------\n",
            "train Loss: 983.4735\n",
            "\n",
            "\n",
            "Training complete in 0m 44s\n",
            "----------\n",
            "Epoch 200/399\n",
            "----------\n",
            "train Loss: 982.3973\n",
            "\n",
            "\n",
            "Training complete in 0m 44s\n",
            "----------\n",
            "Epoch 201/399\n",
            "----------\n",
            "train Loss: 981.3322\n",
            "\n",
            "\n",
            "Training complete in 0m 44s\n",
            "----------\n",
            "Epoch 202/399\n",
            "----------\n",
            "train Loss: 980.2734\n",
            "\n",
            "\n",
            "Training complete in 0m 44s\n",
            "----------\n",
            "Epoch 203/399\n",
            "----------\n",
            "train Loss: 979.2263\n",
            "\n",
            "\n",
            "Training complete in 0m 44s\n",
            "----------\n",
            "Epoch 204/399\n",
            "----------\n",
            "train Loss: 978.1848\n",
            "\n",
            "\n",
            "Training complete in 0m 45s\n",
            "----------\n",
            "Epoch 205/399\n",
            "----------\n",
            "train Loss: 977.1550\n",
            "\n",
            "\n",
            "Training complete in 0m 45s\n",
            "----------\n",
            "Epoch 206/399\n",
            "----------\n",
            "train Loss: 976.1316\n",
            "\n",
            "\n",
            "Training complete in 0m 45s\n",
            "----------\n",
            "Epoch 207/399\n",
            "----------\n",
            "train Loss: 975.1185\n",
            "\n",
            "\n",
            "Training complete in 0m 45s\n",
            "----------\n",
            "Epoch 208/399\n",
            "----------\n",
            "train Loss: 974.1133\n",
            "\n",
            "\n",
            "Training complete in 0m 45s\n",
            "----------\n",
            "Epoch 209/399\n",
            "----------\n",
            "train Loss: 973.1175\n",
            "\n",
            "\n",
            "Training complete in 0m 46s\n",
            "----------\n",
            "Epoch 210/399\n",
            "----------\n",
            "train Loss: 972.1278\n",
            "\n",
            "\n",
            "Training complete in 0m 46s\n",
            "----------\n",
            "Epoch 211/399\n",
            "----------\n",
            "train Loss: 971.1490\n",
            "\n",
            "\n",
            "Training complete in 0m 46s\n",
            "----------\n",
            "Epoch 212/399\n",
            "----------\n",
            "train Loss: 970.1755\n",
            "\n",
            "\n",
            "Training complete in 0m 46s\n",
            "----------\n",
            "Epoch 213/399\n",
            "----------\n",
            "train Loss: 969.2102\n",
            "\n",
            "\n",
            "Training complete in 0m 47s\n",
            "----------\n",
            "Epoch 214/399\n",
            "----------\n",
            "train Loss: 968.2553\n",
            "\n",
            "\n",
            "Training complete in 0m 47s\n",
            "----------\n",
            "Epoch 215/399\n",
            "----------\n",
            "train Loss: 967.3071\n",
            "\n",
            "\n",
            "Training complete in 0m 47s\n",
            "----------\n",
            "Epoch 216/399\n",
            "----------\n",
            "train Loss: 966.3659\n",
            "\n",
            "\n",
            "Training complete in 0m 47s\n",
            "----------\n",
            "Epoch 217/399\n",
            "----------\n",
            "train Loss: 965.4326\n",
            "\n",
            "\n",
            "Training complete in 0m 47s\n",
            "----------\n",
            "Epoch 218/399\n",
            "----------\n",
            "train Loss: 964.5040\n",
            "\n",
            "\n",
            "Training complete in 0m 48s\n",
            "----------\n",
            "Epoch 219/399\n",
            "----------\n",
            "train Loss: 963.5875\n",
            "\n",
            "\n",
            "Training complete in 0m 48s\n",
            "----------\n",
            "Epoch 220/399\n",
            "----------\n",
            "train Loss: 962.6741\n",
            "\n",
            "\n",
            "Training complete in 0m 48s\n",
            "----------\n",
            "Epoch 221/399\n",
            "----------\n",
            "train Loss: 961.7712\n",
            "\n",
            "\n",
            "Training complete in 0m 48s\n",
            "----------\n",
            "Epoch 222/399\n",
            "----------\n",
            "train Loss: 960.8726\n",
            "\n",
            "\n",
            "Training complete in 0m 49s\n",
            "----------\n",
            "Epoch 223/399\n",
            "----------\n",
            "train Loss: 959.9843\n",
            "\n",
            "\n",
            "Training complete in 0m 49s\n",
            "----------\n",
            "Epoch 224/399\n",
            "----------\n",
            "train Loss: 959.1003\n",
            "\n",
            "\n",
            "Training complete in 0m 49s\n",
            "----------\n",
            "Epoch 225/399\n",
            "----------\n",
            "train Loss: 958.2228\n",
            "\n",
            "\n",
            "Training complete in 0m 49s\n",
            "----------\n",
            "Epoch 226/399\n",
            "----------\n",
            "train Loss: 957.3542\n",
            "\n",
            "\n",
            "Training complete in 0m 49s\n",
            "----------\n",
            "Epoch 227/399\n",
            "----------\n",
            "train Loss: 956.4904\n",
            "\n",
            "\n",
            "Training complete in 0m 50s\n",
            "----------\n",
            "Epoch 228/399\n",
            "----------\n",
            "train Loss: 955.6362\n",
            "\n",
            "\n",
            "Training complete in 0m 50s\n",
            "----------\n",
            "Epoch 229/399\n",
            "----------\n",
            "train Loss: 954.7855\n",
            "\n",
            "\n",
            "Training complete in 0m 50s\n",
            "----------\n",
            "Epoch 230/399\n",
            "----------\n",
            "train Loss: 953.9412\n",
            "\n",
            "\n",
            "Training complete in 0m 50s\n",
            "----------\n",
            "Epoch 231/399\n",
            "----------\n",
            "train Loss: 953.1031\n",
            "\n",
            "\n",
            "Training complete in 0m 50s\n",
            "----------\n",
            "Epoch 232/399\n",
            "----------\n",
            "train Loss: 952.2731\n",
            "\n",
            "\n",
            "Training complete in 0m 51s\n",
            "----------\n",
            "Epoch 233/399\n",
            "----------\n",
            "train Loss: 951.4492\n",
            "\n",
            "\n",
            "Training complete in 0m 51s\n",
            "----------\n",
            "Epoch 234/399\n",
            "----------\n",
            "train Loss: 950.6306\n",
            "\n",
            "\n",
            "Training complete in 0m 51s\n",
            "----------\n",
            "Epoch 235/399\n",
            "----------\n",
            "train Loss: 949.8184\n",
            "\n",
            "\n",
            "Training complete in 0m 51s\n",
            "----------\n",
            "Epoch 236/399\n",
            "----------\n",
            "train Loss: 949.0136\n",
            "\n",
            "\n",
            "Training complete in 0m 52s\n",
            "----------\n",
            "Epoch 237/399\n",
            "----------\n",
            "train Loss: 948.2136\n",
            "\n",
            "\n",
            "Training complete in 0m 52s\n",
            "----------\n",
            "Epoch 238/399\n",
            "----------\n",
            "train Loss: 947.4208\n",
            "\n",
            "\n",
            "Training complete in 0m 52s\n",
            "----------\n",
            "Epoch 239/399\n",
            "----------\n",
            "train Loss: 946.6315\n",
            "\n",
            "\n",
            "Training complete in 0m 52s\n",
            "----------\n",
            "Epoch 240/399\n",
            "----------\n",
            "train Loss: 945.8497\n",
            "\n",
            "\n",
            "Training complete in 0m 52s\n",
            "----------\n",
            "Epoch 241/399\n",
            "----------\n",
            "train Loss: 945.0724\n",
            "\n",
            "\n",
            "Training complete in 0m 53s\n",
            "----------\n",
            "Epoch 242/399\n",
            "----------\n",
            "train Loss: 944.3006\n",
            "\n",
            "\n",
            "Training complete in 0m 53s\n",
            "----------\n",
            "Epoch 243/399\n",
            "----------\n",
            "train Loss: 943.5355\n",
            "\n",
            "\n",
            "Training complete in 0m 53s\n",
            "----------\n",
            "Epoch 244/399\n",
            "----------\n",
            "train Loss: 942.7755\n",
            "\n",
            "\n",
            "Training complete in 0m 53s\n",
            "----------\n",
            "Epoch 245/399\n",
            "----------\n",
            "train Loss: 942.0211\n",
            "\n",
            "\n",
            "Training complete in 0m 54s\n",
            "----------\n",
            "Epoch 246/399\n",
            "----------\n",
            "train Loss: 941.2700\n",
            "\n",
            "\n",
            "Training complete in 0m 54s\n",
            "----------\n",
            "Epoch 247/399\n",
            "----------\n",
            "train Loss: 940.5287\n",
            "\n",
            "\n",
            "Training complete in 0m 54s\n",
            "----------\n",
            "Epoch 248/399\n",
            "----------\n",
            "train Loss: 939.7902\n",
            "\n",
            "\n",
            "Training complete in 0m 54s\n",
            "----------\n",
            "Epoch 249/399\n",
            "----------\n",
            "train Loss: 939.0564\n",
            "\n",
            "\n",
            "Training complete in 0m 54s\n",
            "----------\n",
            "Epoch 250/399\n",
            "----------\n",
            "train Loss: 938.3283\n",
            "\n",
            "\n",
            "Training complete in 0m 55s\n",
            "----------\n",
            "Epoch 251/399\n",
            "----------\n",
            "train Loss: 937.6052\n",
            "\n",
            "\n",
            "Training complete in 0m 55s\n",
            "----------\n",
            "Epoch 252/399\n",
            "----------\n",
            "train Loss: 936.8862\n",
            "\n",
            "\n",
            "Training complete in 0m 55s\n",
            "----------\n",
            "Epoch 253/399\n",
            "----------\n",
            "train Loss: 936.1754\n",
            "\n",
            "\n",
            "Training complete in 0m 55s\n",
            "----------\n",
            "Epoch 254/399\n",
            "----------\n",
            "train Loss: 935.4655\n",
            "\n",
            "\n",
            "Training complete in 0m 55s\n",
            "----------\n",
            "Epoch 255/399\n",
            "----------\n",
            "train Loss: 934.7634\n",
            "\n",
            "\n",
            "Training complete in 0m 56s\n",
            "----------\n",
            "Epoch 256/399\n",
            "----------\n",
            "train Loss: 934.0659\n",
            "\n",
            "\n",
            "Training complete in 0m 56s\n",
            "----------\n",
            "Epoch 257/399\n",
            "----------\n",
            "train Loss: 933.3719\n",
            "\n",
            "\n",
            "Training complete in 0m 56s\n",
            "----------\n",
            "Epoch 258/399\n",
            "----------\n",
            "train Loss: 932.6848\n",
            "\n",
            "\n",
            "Training complete in 0m 56s\n",
            "----------\n",
            "Epoch 259/399\n",
            "----------\n",
            "train Loss: 932.0002\n",
            "\n",
            "\n",
            "Training complete in 0m 57s\n",
            "----------\n",
            "Epoch 260/399\n",
            "----------\n",
            "train Loss: 931.3215\n",
            "\n",
            "\n",
            "Training complete in 0m 57s\n",
            "----------\n",
            "Epoch 261/399\n",
            "----------\n",
            "train Loss: 930.6473\n",
            "\n",
            "\n",
            "Training complete in 0m 57s\n",
            "----------\n",
            "Epoch 262/399\n",
            "----------\n",
            "train Loss: 929.9781\n",
            "\n",
            "\n",
            "Training complete in 0m 57s\n",
            "----------\n",
            "Epoch 263/399\n",
            "----------\n",
            "train Loss: 929.3116\n",
            "\n",
            "\n",
            "Training complete in 0m 57s\n",
            "----------\n",
            "Epoch 264/399\n",
            "----------\n",
            "train Loss: 928.6500\n",
            "\n",
            "\n",
            "Training complete in 0m 58s\n",
            "----------\n",
            "Epoch 265/399\n",
            "----------\n",
            "train Loss: 927.9941\n",
            "\n",
            "\n",
            "Training complete in 0m 58s\n",
            "----------\n",
            "Epoch 266/399\n",
            "----------\n",
            "train Loss: 927.3417\n",
            "\n",
            "\n",
            "Training complete in 0m 58s\n",
            "----------\n",
            "Epoch 267/399\n",
            "----------\n",
            "train Loss: 926.6956\n",
            "\n",
            "\n",
            "Training complete in 0m 58s\n",
            "----------\n",
            "Epoch 268/399\n",
            "----------\n",
            "train Loss: 926.0519\n",
            "\n",
            "\n",
            "Training complete in 0m 58s\n",
            "----------\n",
            "Epoch 269/399\n",
            "----------\n",
            "train Loss: 925.4140\n",
            "\n",
            "\n",
            "Training complete in 0m 59s\n",
            "----------\n",
            "Epoch 270/399\n",
            "----------\n",
            "train Loss: 924.7766\n",
            "\n",
            "\n",
            "Training complete in 0m 59s\n",
            "----------\n",
            "Epoch 271/399\n",
            "----------\n",
            "train Loss: 924.1468\n",
            "\n",
            "\n",
            "Training complete in 0m 59s\n",
            "----------\n",
            "Epoch 272/399\n",
            "----------\n",
            "train Loss: 923.5193\n",
            "\n",
            "\n",
            "Training complete in 0m 59s\n",
            "----------\n",
            "Epoch 273/399\n",
            "----------\n",
            "train Loss: 922.8984\n",
            "\n",
            "\n",
            "Training complete in 0m 60s\n",
            "----------\n",
            "Epoch 274/399\n",
            "----------\n",
            "train Loss: 922.2783\n",
            "\n",
            "\n",
            "Training complete in 0m 60s\n",
            "----------\n",
            "Epoch 275/399\n",
            "----------\n",
            "train Loss: 921.6644\n",
            "\n",
            "\n",
            "Training complete in 0m 60s\n",
            "----------\n",
            "Epoch 276/399\n",
            "----------\n",
            "train Loss: 921.0538\n",
            "\n",
            "\n",
            "Training complete in 1m 0s\n",
            "----------\n",
            "Epoch 277/399\n",
            "----------\n",
            "train Loss: 920.4478\n",
            "\n",
            "\n",
            "Training complete in 1m 0s\n",
            "----------\n",
            "Epoch 278/399\n",
            "----------\n",
            "train Loss: 919.8455\n",
            "\n",
            "\n",
            "Training complete in 1m 1s\n",
            "----------\n",
            "Epoch 279/399\n",
            "----------\n",
            "train Loss: 919.2459\n",
            "\n",
            "\n",
            "Training complete in 1m 1s\n",
            "----------\n",
            "Epoch 280/399\n",
            "----------\n",
            "train Loss: 918.6509\n",
            "\n",
            "\n",
            "Training complete in 1m 1s\n",
            "----------\n",
            "Epoch 281/399\n",
            "----------\n",
            "train Loss: 918.0607\n",
            "\n",
            "\n",
            "Training complete in 1m 1s\n",
            "----------\n",
            "Epoch 282/399\n",
            "----------\n",
            "train Loss: 917.4730\n",
            "\n",
            "\n",
            "Training complete in 1m 2s\n",
            "----------\n",
            "Epoch 283/399\n",
            "----------\n",
            "train Loss: 916.8885\n",
            "\n",
            "\n",
            "Training complete in 1m 2s\n",
            "----------\n",
            "Epoch 284/399\n",
            "----------\n",
            "train Loss: 916.3093\n",
            "\n",
            "\n",
            "Training complete in 1m 2s\n",
            "----------\n",
            "Epoch 285/399\n",
            "----------\n",
            "train Loss: 915.7330\n",
            "\n",
            "\n",
            "Training complete in 1m 2s\n",
            "----------\n",
            "Epoch 286/399\n",
            "----------\n",
            "train Loss: 915.1599\n",
            "\n",
            "\n",
            "Training complete in 1m 2s\n",
            "----------\n",
            "Epoch 287/399\n",
            "----------\n",
            "train Loss: 914.5912\n",
            "\n",
            "\n",
            "Training complete in 1m 3s\n",
            "----------\n",
            "Epoch 288/399\n",
            "----------\n",
            "train Loss: 914.0256\n",
            "\n",
            "\n",
            "Training complete in 1m 3s\n",
            "----------\n",
            "Epoch 289/399\n",
            "----------\n",
            "train Loss: 913.4634\n",
            "\n",
            "\n",
            "Training complete in 1m 3s\n",
            "----------\n",
            "Epoch 290/399\n",
            "----------\n",
            "train Loss: 912.9056\n",
            "\n",
            "\n",
            "Training complete in 1m 3s\n",
            "----------\n",
            "Epoch 291/399\n",
            "----------\n",
            "train Loss: 912.3499\n",
            "\n",
            "\n",
            "Training complete in 1m 3s\n",
            "----------\n",
            "Epoch 292/399\n",
            "----------\n",
            "train Loss: 911.7975\n",
            "\n",
            "\n",
            "Training complete in 1m 4s\n",
            "----------\n",
            "Epoch 293/399\n",
            "----------\n",
            "train Loss: 911.2498\n",
            "\n",
            "\n",
            "Training complete in 1m 4s\n",
            "----------\n",
            "Epoch 294/399\n",
            "----------\n",
            "train Loss: 910.7052\n",
            "\n",
            "\n",
            "Training complete in 1m 4s\n",
            "----------\n",
            "Epoch 295/399\n",
            "----------\n",
            "train Loss: 910.1635\n",
            "\n",
            "\n",
            "Training complete in 1m 4s\n",
            "----------\n",
            "Epoch 296/399\n",
            "----------\n",
            "train Loss: 909.6232\n",
            "\n",
            "\n",
            "Training complete in 1m 5s\n",
            "----------\n",
            "Epoch 297/399\n",
            "----------\n",
            "train Loss: 909.0912\n",
            "\n",
            "\n",
            "Training complete in 1m 5s\n",
            "----------\n",
            "Epoch 298/399\n",
            "----------\n",
            "train Loss: 908.5579\n",
            "\n",
            "\n",
            "Training complete in 1m 5s\n",
            "----------\n",
            "Epoch 299/399\n",
            "----------\n",
            "train Loss: 908.0300\n",
            "\n",
            "\n",
            "Training complete in 1m 5s\n",
            "----------\n",
            "Epoch 300/399\n",
            "----------\n",
            "train Loss: 907.5040\n",
            "\n",
            "\n",
            "Training complete in 1m 5s\n",
            "----------\n",
            "Epoch 301/399\n",
            "----------\n",
            "train Loss: 906.9810\n",
            "\n",
            "\n",
            "Training complete in 1m 6s\n",
            "----------\n",
            "Epoch 302/399\n",
            "----------\n",
            "train Loss: 906.4623\n",
            "\n",
            "\n",
            "Training complete in 1m 6s\n",
            "----------\n",
            "Epoch 303/399\n",
            "----------\n",
            "train Loss: 905.9471\n",
            "\n",
            "\n",
            "Training complete in 1m 6s\n",
            "----------\n",
            "Epoch 304/399\n",
            "----------\n",
            "train Loss: 905.4341\n",
            "\n",
            "\n",
            "Training complete in 1m 6s\n",
            "----------\n",
            "Epoch 305/399\n",
            "----------\n",
            "train Loss: 904.9220\n",
            "\n",
            "\n",
            "Training complete in 1m 7s\n",
            "----------\n",
            "Epoch 306/399\n",
            "----------\n",
            "train Loss: 904.4182\n",
            "\n",
            "\n",
            "Training complete in 1m 7s\n",
            "----------\n",
            "Epoch 307/399\n",
            "----------\n",
            "train Loss: 903.9136\n",
            "\n",
            "\n",
            "Training complete in 1m 7s\n",
            "----------\n",
            "Epoch 308/399\n",
            "----------\n",
            "train Loss: 903.4121\n",
            "\n",
            "\n",
            "Training complete in 1m 7s\n",
            "----------\n",
            "Epoch 309/399\n",
            "----------\n",
            "train Loss: 902.9149\n",
            "\n",
            "\n",
            "Training complete in 1m 7s\n",
            "----------\n",
            "Epoch 310/399\n",
            "----------\n",
            "train Loss: 902.4189\n",
            "\n",
            "\n",
            "Training complete in 1m 8s\n",
            "----------\n",
            "Epoch 311/399\n",
            "----------\n",
            "train Loss: 901.9258\n",
            "\n",
            "\n",
            "Training complete in 1m 8s\n",
            "----------\n",
            "Epoch 312/399\n",
            "----------\n",
            "train Loss: 901.4380\n",
            "\n",
            "\n",
            "Training complete in 1m 8s\n",
            "----------\n",
            "Epoch 313/399\n",
            "----------\n",
            "train Loss: 900.9501\n",
            "\n",
            "\n",
            "Training complete in 1m 8s\n",
            "----------\n",
            "Epoch 314/399\n",
            "----------\n",
            "train Loss: 900.4678\n",
            "\n",
            "\n",
            "Training complete in 1m 8s\n",
            "----------\n",
            "Epoch 315/399\n",
            "----------\n",
            "train Loss: 899.9872\n",
            "\n",
            "\n",
            "Training complete in 1m 9s\n",
            "----------\n",
            "Epoch 316/399\n",
            "----------\n",
            "train Loss: 899.5073\n",
            "\n",
            "\n",
            "Training complete in 1m 9s\n",
            "----------\n",
            "Epoch 317/399\n",
            "----------\n",
            "train Loss: 899.0331\n",
            "\n",
            "\n",
            "Training complete in 1m 9s\n",
            "----------\n",
            "Epoch 318/399\n",
            "----------\n",
            "train Loss: 898.5586\n",
            "\n",
            "\n",
            "Training complete in 1m 9s\n",
            "----------\n",
            "Epoch 319/399\n",
            "----------\n",
            "train Loss: 898.0889\n",
            "\n",
            "\n",
            "Training complete in 1m 10s\n",
            "----------\n",
            "Epoch 320/399\n",
            "----------\n",
            "train Loss: 897.6234\n",
            "\n",
            "\n",
            "Training complete in 1m 10s\n",
            "----------\n",
            "Epoch 321/399\n",
            "----------\n",
            "train Loss: 897.1573\n",
            "\n",
            "\n",
            "Training complete in 1m 10s\n",
            "----------\n",
            "Epoch 322/399\n",
            "----------\n",
            "train Loss: 896.6943\n",
            "\n",
            "\n",
            "Training complete in 1m 10s\n",
            "----------\n",
            "Epoch 323/399\n",
            "----------\n",
            "train Loss: 896.2373\n",
            "\n",
            "\n",
            "Training complete in 1m 10s\n",
            "----------\n",
            "Epoch 324/399\n",
            "----------\n",
            "train Loss: 895.7794\n",
            "\n",
            "\n",
            "Training complete in 1m 11s\n",
            "----------\n",
            "Epoch 325/399\n",
            "----------\n",
            "train Loss: 895.3257\n",
            "\n",
            "\n",
            "Training complete in 1m 11s\n",
            "----------\n",
            "Epoch 326/399\n",
            "----------\n",
            "train Loss: 894.8741\n",
            "\n",
            "\n",
            "Training complete in 1m 11s\n",
            "----------\n",
            "Epoch 327/399\n",
            "----------\n",
            "train Loss: 894.4250\n",
            "\n",
            "\n",
            "Training complete in 1m 11s\n",
            "----------\n",
            "Epoch 328/399\n",
            "----------\n",
            "train Loss: 893.9767\n",
            "\n",
            "\n",
            "Training complete in 1m 11s\n",
            "----------\n",
            "Epoch 329/399\n",
            "----------\n",
            "train Loss: 893.5342\n",
            "\n",
            "\n",
            "Training complete in 1m 12s\n",
            "----------\n",
            "Epoch 330/399\n",
            "----------\n",
            "train Loss: 893.0923\n",
            "\n",
            "\n",
            "Training complete in 1m 12s\n",
            "----------\n",
            "Epoch 331/399\n",
            "----------\n",
            "train Loss: 892.6514\n",
            "\n",
            "\n",
            "Training complete in 1m 12s\n",
            "----------\n",
            "Epoch 332/399\n",
            "----------\n",
            "train Loss: 892.2151\n",
            "\n",
            "\n",
            "Training complete in 1m 12s\n",
            "----------\n",
            "Epoch 333/399\n",
            "----------\n",
            "train Loss: 891.7803\n",
            "\n",
            "\n",
            "Training complete in 1m 13s\n",
            "----------\n",
            "Epoch 334/399\n",
            "----------\n",
            "train Loss: 891.3480\n",
            "\n",
            "\n",
            "Training complete in 1m 13s\n",
            "----------\n",
            "Epoch 335/399\n",
            "----------\n",
            "train Loss: 890.9170\n",
            "\n",
            "\n",
            "Training complete in 1m 13s\n",
            "----------\n",
            "Epoch 336/399\n",
            "----------\n",
            "train Loss: 890.4918\n",
            "\n",
            "\n",
            "Training complete in 1m 13s\n",
            "----------\n",
            "Epoch 337/399\n",
            "----------\n",
            "train Loss: 890.0665\n",
            "\n",
            "\n",
            "Training complete in 1m 13s\n",
            "----------\n",
            "Epoch 338/399\n",
            "----------\n",
            "train Loss: 889.6431\n",
            "\n",
            "\n",
            "Training complete in 1m 14s\n",
            "----------\n",
            "Epoch 339/399\n",
            "----------\n",
            "train Loss: 889.2223\n",
            "\n",
            "\n",
            "Training complete in 1m 14s\n",
            "----------\n",
            "Epoch 340/399\n",
            "----------\n",
            "train Loss: 888.8057\n",
            "\n",
            "\n",
            "Training complete in 1m 14s\n",
            "----------\n",
            "Epoch 341/399\n",
            "----------\n",
            "train Loss: 888.3881\n",
            "\n",
            "\n",
            "Training complete in 1m 14s\n",
            "----------\n",
            "Epoch 342/399\n",
            "----------\n",
            "train Loss: 887.9730\n",
            "\n",
            "\n",
            "Training complete in 1m 15s\n",
            "----------\n",
            "Epoch 343/399\n",
            "----------\n",
            "train Loss: 887.5640\n",
            "\n",
            "\n",
            "Training complete in 1m 15s\n",
            "----------\n",
            "Epoch 344/399\n",
            "----------\n",
            "train Loss: 887.1543\n",
            "\n",
            "\n",
            "Training complete in 1m 15s\n",
            "----------\n",
            "Epoch 345/399\n",
            "----------\n",
            "train Loss: 886.7471\n",
            "\n",
            "\n",
            "Training complete in 1m 15s\n",
            "----------\n",
            "Epoch 346/399\n",
            "----------\n",
            "train Loss: 886.3412\n",
            "\n",
            "\n",
            "Training complete in 1m 15s\n",
            "----------\n",
            "Epoch 347/399\n",
            "----------\n",
            "train Loss: 885.9393\n",
            "\n",
            "\n",
            "Training complete in 1m 16s\n",
            "----------\n",
            "Epoch 348/399\n",
            "----------\n",
            "train Loss: 885.5381\n",
            "\n",
            "\n",
            "Training complete in 1m 16s\n",
            "----------\n",
            "Epoch 349/399\n",
            "----------\n",
            "train Loss: 885.1384\n",
            "\n",
            "\n",
            "Training complete in 1m 16s\n",
            "----------\n",
            "Epoch 350/399\n",
            "----------\n",
            "train Loss: 884.7436\n",
            "\n",
            "\n",
            "Training complete in 1m 16s\n",
            "----------\n",
            "Epoch 351/399\n",
            "----------\n",
            "train Loss: 884.3478\n",
            "\n",
            "\n",
            "Training complete in 1m 16s\n",
            "----------\n",
            "Epoch 352/399\n",
            "----------\n",
            "train Loss: 883.9557\n",
            "\n",
            "\n",
            "Training complete in 1m 17s\n",
            "----------\n",
            "Epoch 353/399\n",
            "----------\n",
            "train Loss: 883.5668\n",
            "\n",
            "\n",
            "Training complete in 1m 17s\n",
            "----------\n",
            "Epoch 354/399\n",
            "----------\n",
            "train Loss: 883.1779\n",
            "\n",
            "\n",
            "Training complete in 1m 17s\n",
            "----------\n",
            "Epoch 355/399\n",
            "----------\n",
            "train Loss: 882.7917\n",
            "\n",
            "\n",
            "Training complete in 1m 17s\n",
            "----------\n",
            "Epoch 356/399\n",
            "----------\n",
            "train Loss: 882.4062\n",
            "\n",
            "\n",
            "Training complete in 1m 18s\n",
            "----------\n",
            "Epoch 357/399\n",
            "----------\n",
            "train Loss: 882.0236\n",
            "\n",
            "\n",
            "Training complete in 1m 18s\n",
            "----------\n",
            "Epoch 358/399\n",
            "----------\n",
            "train Loss: 881.6445\n",
            "\n",
            "\n",
            "Training complete in 1m 18s\n",
            "----------\n",
            "Epoch 359/399\n",
            "----------\n",
            "train Loss: 881.2657\n",
            "\n",
            "\n",
            "Training complete in 1m 18s\n",
            "----------\n",
            "Epoch 360/399\n",
            "----------\n",
            "train Loss: 880.8884\n",
            "\n",
            "\n",
            "Training complete in 1m 18s\n",
            "----------\n",
            "Epoch 361/399\n",
            "----------\n",
            "train Loss: 880.5154\n",
            "\n",
            "\n",
            "Training complete in 1m 19s\n",
            "----------\n",
            "Epoch 362/399\n",
            "----------\n",
            "train Loss: 880.1429\n",
            "\n",
            "\n",
            "Training complete in 1m 19s\n",
            "----------\n",
            "Epoch 363/399\n",
            "----------\n",
            "train Loss: 879.7714\n",
            "\n",
            "\n",
            "Training complete in 1m 19s\n",
            "----------\n",
            "Epoch 364/399\n",
            "----------\n",
            "train Loss: 879.4025\n",
            "\n",
            "\n",
            "Training complete in 1m 19s\n",
            "----------\n",
            "Epoch 365/399\n",
            "----------\n",
            "train Loss: 879.0352\n",
            "\n",
            "\n",
            "Training complete in 1m 20s\n",
            "----------\n",
            "Epoch 366/399\n",
            "----------\n",
            "train Loss: 878.6706\n",
            "\n",
            "\n",
            "Training complete in 1m 20s\n",
            "----------\n",
            "Epoch 367/399\n",
            "----------\n",
            "train Loss: 878.3079\n",
            "\n",
            "\n",
            "Training complete in 1m 20s\n",
            "----------\n",
            "Epoch 368/399\n",
            "----------\n",
            "train Loss: 877.9457\n",
            "\n",
            "\n",
            "Training complete in 1m 20s\n",
            "----------\n",
            "Epoch 369/399\n",
            "----------\n",
            "train Loss: 877.5876\n",
            "\n",
            "\n",
            "Training complete in 1m 20s\n",
            "----------\n",
            "Epoch 370/399\n",
            "----------\n",
            "train Loss: 877.2288\n",
            "\n",
            "\n",
            "Training complete in 1m 21s\n",
            "----------\n",
            "Epoch 371/399\n",
            "----------\n",
            "train Loss: 876.8734\n",
            "\n",
            "\n",
            "Training complete in 1m 21s\n",
            "----------\n",
            "Epoch 372/399\n",
            "----------\n",
            "train Loss: 876.5186\n",
            "\n",
            "\n",
            "Training complete in 1m 21s\n",
            "----------\n",
            "Epoch 373/399\n",
            "----------\n",
            "train Loss: 876.1669\n",
            "\n",
            "\n",
            "Training complete in 1m 21s\n",
            "----------\n",
            "Epoch 374/399\n",
            "----------\n",
            "train Loss: 875.8154\n",
            "\n",
            "\n",
            "Training complete in 1m 22s\n",
            "----------\n",
            "Epoch 375/399\n",
            "----------\n",
            "train Loss: 875.4675\n",
            "\n",
            "\n",
            "Training complete in 1m 22s\n",
            "----------\n",
            "Epoch 376/399\n",
            "----------\n",
            "train Loss: 875.1187\n",
            "\n",
            "\n",
            "Training complete in 1m 22s\n",
            "----------\n",
            "Epoch 377/399\n",
            "----------\n",
            "train Loss: 874.7736\n",
            "\n",
            "\n",
            "Training complete in 1m 22s\n",
            "----------\n",
            "Epoch 378/399\n",
            "----------\n",
            "train Loss: 874.4310\n",
            "\n",
            "\n",
            "Training complete in 1m 22s\n",
            "----------\n",
            "Epoch 379/399\n",
            "----------\n",
            "train Loss: 874.0877\n",
            "\n",
            "\n",
            "Training complete in 1m 23s\n",
            "----------\n",
            "Epoch 380/399\n",
            "----------\n",
            "train Loss: 873.7471\n",
            "\n",
            "\n",
            "Training complete in 1m 23s\n",
            "----------\n",
            "Epoch 381/399\n",
            "----------\n",
            "train Loss: 873.4082\n",
            "\n",
            "\n",
            "Training complete in 1m 23s\n",
            "----------\n",
            "Epoch 382/399\n",
            "----------\n",
            "train Loss: 873.0698\n",
            "\n",
            "\n",
            "Training complete in 1m 23s\n",
            "----------\n",
            "Epoch 383/399\n",
            "----------\n",
            "train Loss: 872.7359\n",
            "\n",
            "\n",
            "Training complete in 1m 24s\n",
            "----------\n",
            "Epoch 384/399\n",
            "----------\n",
            "train Loss: 872.4027\n",
            "\n",
            "\n",
            "Training complete in 1m 24s\n",
            "----------\n",
            "Epoch 385/399\n",
            "----------\n",
            "train Loss: 872.0685\n",
            "\n",
            "\n",
            "Training complete in 1m 24s\n",
            "----------\n",
            "Epoch 386/399\n",
            "----------\n",
            "train Loss: 871.7394\n",
            "\n",
            "\n",
            "Training complete in 1m 24s\n",
            "----------\n",
            "Epoch 387/399\n",
            "----------\n",
            "train Loss: 871.4103\n",
            "\n",
            "\n",
            "Training complete in 1m 24s\n",
            "----------\n",
            "Epoch 388/399\n",
            "----------\n",
            "train Loss: 871.0818\n",
            "\n",
            "\n",
            "Training complete in 1m 25s\n",
            "----------\n",
            "Epoch 389/399\n",
            "----------\n",
            "train Loss: 870.7560\n",
            "\n",
            "\n",
            "Training complete in 1m 25s\n",
            "----------\n",
            "Epoch 390/399\n",
            "----------\n",
            "train Loss: 870.4339\n",
            "\n",
            "\n",
            "Training complete in 1m 25s\n",
            "----------\n",
            "Epoch 391/399\n",
            "----------\n",
            "train Loss: 870.1084\n",
            "\n",
            "\n",
            "Training complete in 1m 25s\n",
            "----------\n",
            "Epoch 392/399\n",
            "----------\n",
            "train Loss: 869.7880\n",
            "\n",
            "\n",
            "Training complete in 1m 26s\n",
            "----------\n",
            "Epoch 393/399\n",
            "----------\n",
            "train Loss: 869.4682\n",
            "\n",
            "\n",
            "Training complete in 1m 26s\n",
            "----------\n",
            "Epoch 394/399\n",
            "----------\n",
            "train Loss: 869.1495\n",
            "\n",
            "\n",
            "Training complete in 1m 26s\n",
            "----------\n",
            "Epoch 395/399\n",
            "----------\n",
            "train Loss: 868.8326\n",
            "\n",
            "\n",
            "Training complete in 1m 26s\n",
            "----------\n",
            "Epoch 396/399\n",
            "----------\n",
            "train Loss: 868.5182\n",
            "\n",
            "\n",
            "Training complete in 1m 26s\n",
            "----------\n",
            "Epoch 397/399\n",
            "----------\n",
            "train Loss: 868.2040\n",
            "\n",
            "\n",
            "Training complete in 1m 27s\n",
            "----------\n",
            "Epoch 398/399\n",
            "----------\n",
            "train Loss: 867.8922\n",
            "\n",
            "\n",
            "Training complete in 1m 27s\n",
            "----------\n",
            "Epoch 399/399\n",
            "----------\n",
            "train Loss: 867.5800\n",
            "\n",
            "\n",
            "Training complete in 1m 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in modified_model.named_parameters():\n",
        "  if (name == 'classifier.4.weight') or (name == 'classifier.4.bias'):\n",
        "    print(name, param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2y-EVYDgpCU",
        "outputId": "be504ef4-2d5c-4827-b8fc-8f32a54a8c78"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifier.4.weight Parameter containing:\n",
            "tensor([[[[ 8.0498e+00]],\n",
            "\n",
            "         [[ 2.7167e+00]],\n",
            "\n",
            "         [[ 1.8490e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6232e+00]],\n",
            "\n",
            "         [[ 2.0870e+00]],\n",
            "\n",
            "         [[-2.7501e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.2070e-02]],\n",
            "\n",
            "         [[-3.3037e-03]],\n",
            "\n",
            "         [[-2.2896e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8999e-02]],\n",
            "\n",
            "         [[-3.9636e-02]],\n",
            "\n",
            "         [[-1.4570e-02]]]], device='cuda:0', requires_grad=True)\n",
            "classifier.4.bias Parameter containing:\n",
            "tensor([30.1415,  0.0376], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}