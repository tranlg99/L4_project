{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "239cca92",
      "metadata": {
        "id": "239cca92",
        "outputId": "12b0b0e6-c547-4b6f-e961-a3d54aa0fd57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connecting drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing requirements\n",
        "!pip install imageio==2.19.3\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install tensorboardX==2.2\n",
        "!pip install einops==0.4.1\n",
        "!pip install scikit-learn==1.1.1\n",
        "!pip install matplotlib==3.5.1\n",
        "!pip install protobuf==3.20.0\n",
        "!pip install fire==0.4.0\n",
        "!pip install moviepy==1.0.3"
      ],
      "metadata": {
        "id": "daqRwkpfAq6L"
      },
      "id": "daqRwkpfAq6L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unziping frames into data folder\n",
        "!mkdir data\n",
        "!unzip /content/drive/MyDrive/frames.zip -d data"
      ],
      "metadata": {
        "id": "pBG51Q0rCBRe"
      },
      "id": "pBG51Q0rCBRe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/drive_folder/pips/')\n",
        "import time\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import saverloader\n",
        "import imageio as imageio\n",
        "from nets.pips import Pips\n",
        "import utils.improc\n",
        "import random\n",
        "import glob\n",
        "from utils.basic import print_, print_stats\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "O_R-IzS1EPcy"
      },
      "id": "O_R-IzS1EPcy",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading their reference model\n",
        "!bash /content/drive/MyDrive/drive_folder/pips/get_reference_model.sh"
      ],
      "metadata": {
        "id": "VngwyXNrAuQd"
      },
      "id": "VngwyXNrAuQd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_weights):\n",
        "  model = Pips(stride=4).cuda()\n",
        "  parameters = list(model.parameters())\n",
        "  _ = saverloader.load(model_weights, model)\n",
        "  global_step = 0\n",
        "  model.eval()\n",
        "  return model"
      ],
      "metadata": {
        "id": "jWzwnNKZKFyj"
      },
      "id": "jWzwnNKZKFyj",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random.seed(125)\n",
        "# np.random.seed(125)\n",
        "\n",
        "def run_model(model, rgbs, N, sw):\n",
        "    rgbs = rgbs.cuda().float() # B, S, C, H, W\n",
        "\n",
        "    B, S, C, H, W = rgbs.shape\n",
        "    rgbs_ = rgbs.reshape(B*S, C, H, W)\n",
        "    H_, W_ = 360, 640\n",
        "    rgbs_ = F.interpolate(rgbs_, (H_, W_), mode='bilinear')\n",
        "    H, W = H_, W_\n",
        "    rgbs = rgbs_.reshape(B, S, C, H, W)\n",
        "\n",
        "    # pick N points to track; we'll use a uniform grid\n",
        "    N_ = np.sqrt(N).round().astype(np.int32)\n",
        "    grid_y, grid_x = utils.basic.meshgrid2d(B, N_, N_, stack=False, norm=False, device='cuda')\n",
        "    grid_y = 8 + grid_y.reshape(B, -1)/float(N_-1) * (H-16)\n",
        "    grid_x = 8 + grid_x.reshape(B, -1)/float(N_-1) * (W-16)\n",
        "    xy = torch.stack([grid_x, grid_y], dim=-1) # B, N_*N_, 2\n",
        "    _, S, C, H, W = rgbs.shape\n",
        "\n",
        "    print_stats('rgbs', rgbs)\n",
        "    preds, preds_anim, vis_e, stats = model(xy, rgbs, iters=6)\n",
        "    trajs_e = preds[-1]\n",
        "    print_stats('trajs_e', trajs_e)\n",
        "    \n",
        "    # pad = 50\n",
        "    # rgbs = F.pad(rgbs.reshape(B*S, 3, H, W), (pad, pad, pad, pad), 'constant', 0).reshape(B, S, 3, H+pad*2, W+pad*2)\n",
        "    # trajs_e = trajs_e + pad\n",
        "    \n",
        "    # if sw is not None and sw.save_this:\n",
        "    #     linewidth = 2\n",
        "\n",
        "    #     # visualize the input\n",
        "    #     o1 = sw.summ_rgbs('inputs/rgbs', utils.improc.preprocess_color(rgbs[0:1]).unbind(1))\n",
        "    #     # visualize the trajs overlaid on the rgbs\n",
        "    #     o2 = sw.summ_traj2ds_on_rgbs('outputs/trajs_on_rgbs', trajs_e[0:1], utils.improc.preprocess_color(rgbs[0:1]), cmap='spring', linewidth=linewidth)\n",
        "    #     # visualize the trajs alone\n",
        "    #     o3 = sw.summ_traj2ds_on_rgbs('outputs/trajs_on_black', trajs_e[0:1], torch.ones_like(rgbs[0:1])*-0.5, cmap='spring', linewidth=linewidth)\n",
        "    #     # concat these for a synced wide vis\n",
        "    #     wide_cat = torch.cat([o1, o2, o3], dim=-1)\n",
        "    #     sw.summ_rgbs('outputs/wide_cat', wide_cat.unbind(1))\n",
        "\n",
        "    #     # write to disk, in case that's more convenient\n",
        "    #     wide_list = list(wide_cat.unbind(1))\n",
        "    #     wide_list = [wide[0].permute(1,2,0).cpu().numpy() for wide in wide_list]\n",
        "    #     wide_list = [Image.fromarray(wide) for wide in wide_list]\n",
        "    #     out_fn = './out_%d.gif' % sw.global_step\n",
        "    #     wide_list[0].save(out_fn, save_all=True, append_images=wide_list[1:])\n",
        "    #     print('saved %s' % out_fn)\n",
        "\n",
        "    #     # alternate vis\n",
        "    #     sw.summ_traj2ds_on_rgbs2('outputs/trajs_on_rgbs2', trajs_e[0:1], vis_e[0:1], utils.improc.preprocess_color(rgbs[0:1]))\n",
        "        \n",
        "    #     # animation of inference iterations\n",
        "    #     rgb_vis = []\n",
        "    #     for trajs_e_ in preds_anim:\n",
        "    #         trajs_e_ = trajs_e_ + pad\n",
        "    #         rgb_vis.append(sw.summ_traj2ds_on_rgb('', trajs_e_[0:1], torch.mean(utils.improc.preprocess_color(rgbs[0:1]), dim=1), cmap='spring', linewidth=linewidth, only_return=True))\n",
        "    #     sw.summ_rgbs('outputs/animated_trajs_on_rgb', rgb_vis)\n",
        "\n",
        "# return vis??\n",
        "    return trajs_e"
      ],
      "metadata": {
        "id": "rw1p5vpiE6l-"
      },
      "id": "rw1p5vpiE6l-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(pips_model, video_name, npy_file):\n",
        "    ## choose hyps\n",
        "    B = 1\n",
        "    S = 8\n",
        "    N = 16**2 # number of points to track\n",
        "\n",
        "    filenames = glob.glob('/data/content/frames/'+video_name+'/*.jpg')\n",
        "    filenames = sorted(filenames)\n",
        "    max_iters = len(filenames)//S # run each unique subsequence\n",
        "\n",
        "    global_step = 0\n",
        "\n",
        "    model = pips_model\n",
        "\n",
        "    print(global_step)\n",
        "    print(max_iters)\n",
        "    while global_step < max_iters:\n",
        "      \n",
        "        read_start_time = time.time()\n",
        "        \n",
        "        global_step += 1\n",
        "\n",
        "        try:\n",
        "            rgbs = []\n",
        "            for s in range(S):\n",
        "                fn = filenames[(global_step-1)*S+s]\n",
        "                if s==0:\n",
        "                    print('start frame', fn)\n",
        "                im = imageio.imread(fn)\n",
        "                im = im.astype(np.uint8)\n",
        "                rgbs.append(torch.from_numpy(im).permute(2,0,1))\n",
        "            rgbs = torch.stack(rgbs, dim=0).unsqueeze(0) # 1, S, C, H, W\n",
        "\n",
        "            read_time = time.time()-read_start_time\n",
        "            iter_start_time = time.time()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                \n",
        "                trajs_e = run_model(model, rgbs, N)\n",
        "\n",
        "            iter_time = time.time()-iter_start_time\n",
        "            print('%s; step %06d/%d; rtime %.2f; itime %.2f' % (\n",
        "                global_step, max_iters, read_time, iter_time))\n",
        "            \n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print('error', e)\n",
        "            "
      ],
      "metadata": {
        "id": "MZn_pJbKIV_l"
      },
      "id": "MZn_pJbKIV_l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('reference_model')"
      ],
      "metadata": {
        "id": "LTZQnKzeKl6r",
        "outputId": "8fb38c08-7679-4bf3-83e8-e563c1297411",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "id": "LTZQnKzeKl6r",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7963afff1a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reference_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'create_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tempfile import TemporaryFile\n",
        "# create folder for numpy files\n",
        "\n",
        "\n",
        "for video_name in  os.listdir(\"/data/content/frames\"):\n",
        "  outfile = TemporaryFile() # create a np file\n",
        "  x = np.array() # create array\n",
        "  run_model(model, video_name, x)\n",
        "  np.save(outfile, x) # save numpy file \n",
        "\n",
        "# zip all numpy files\n",
        "# cp NumPy zip file into drive"
      ],
      "metadata": {
        "id": "dDhyu9SPG6TL"
      },
      "id": "dDhyu9SPG6TL",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}