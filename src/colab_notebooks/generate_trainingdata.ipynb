{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Script for Generating Training Data from Frames using PIPs\n",
        "https://github.com/aharley/pips"
      ],
      "metadata": {
        "id": "7aDztnqsvgfZ"
      },
      "id": "7aDztnqsvgfZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial set up\n",
        "Connection to MyDrive, requirements, imports, downloading models weights"
      ],
      "metadata": {
        "id": "II3QRFFivngi"
      },
      "id": "II3QRFFivngi"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "239cca92",
      "metadata": {
        "id": "239cca92",
        "outputId": "c1299298-d73e-46fb-965a-d4f674936252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connecting drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing requirements\n",
        "!pip install imageio==2.19.3\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install einops==0.4.1\n",
        "!pip install scikit-learn==1.1.1\n",
        "!pip install matplotlib==3.5.1\n",
        "!pip install protobuf==3.20.0\n",
        "!pip install fire==0.4.0"
      ],
      "metadata": {
        "id": "daqRwkpfAq6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9924846d-e311-4c5f-f503-dc3806297325"
      },
      "id": "daqRwkpfAq6L",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.19.3\n",
            "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio==2.19.3) (1.21.6)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, imageio\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed imageio-2.19.3 pillow-9.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python==4.6.0.66 in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python==4.6.0.66) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops==0.4.1\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==1.1.1\n",
            "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (1.21.6)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "Successfully installed scikit-learn-1.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (23.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1) (1.15.0)\n",
            "Installing collected packages: fonttools, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed fonttools-4.38.0 matplotlib-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.0\n",
            "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.58.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.18.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fire==0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire==0.4.0) (2.2.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=37b8b23a3607aba7ecf60915e9f672c4b7aa1df172fc207bf85ee83951e6c411\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/drive_folder/pips')\n",
        "import time\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import saverloader\n",
        "from nets.pips import Pips\n",
        "import utils.improc\n",
        "import random\n",
        "import glob\n",
        "from utils.basic import print_, print_stats\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import imageio.v2 as imageio\n",
        "from csv import writer"
      ],
      "metadata": {
        "id": "O_R-IzS1EPcy"
      },
      "id": "O_R-IzS1EPcy",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading their reference model\n",
        "!bash /content/drive/MyDrive/drive_folder/pips/get_reference_model.sh"
      ],
      "metadata": {
        "id": "VngwyXNrAuQd",
        "outputId": "f38b4da2-381b-444a-dfe0-9e32970e671c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VngwyXNrAuQd",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading the model from dropbox...\n",
            "--2023-02-03 09:26:35--  https://www.dropbox.com/s/hbo7ns4vfx1sejp/reference_model.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6025:18::a27d:4512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/hbo7ns4vfx1sejp/reference_model.tar.gz [following]\n",
            "--2023-02-03 09:26:36--  https://www.dropbox.com/s/raw/hbo7ns4vfx1sejp/reference_model.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com/cd/0/inline/B1zYnC75jH2ka3xAnK4ffiHU0bmAw7IEpSCt6M42mxMP8y_HvJuSWuumy7oZt0XBJZRBNyJaT_2rKQTMgxRUPL8fq88Fi1kkFY0Ubma9jdnIXToWosnB57qaejKmzHjdXPsA_RQUgCXE-4TlE9BCEyKLawGEHzBnmfGt-IjjTqZUZw/file# [following]\n",
            "--2023-02-03 09:26:36--  https://uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com/cd/0/inline/B1zYnC75jH2ka3xAnK4ffiHU0bmAw7IEpSCt6M42mxMP8y_HvJuSWuumy7oZt0XBJZRBNyJaT_2rKQTMgxRUPL8fq88Fi1kkFY0Ubma9jdnIXToWosnB57qaejKmzHjdXPsA_RQUgCXE-4TlE9BCEyKLawGEHzBnmfGt-IjjTqZUZw/file\n",
            "Resolving uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com (uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com)... 162.125.64.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com (uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com)|162.125.64.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B1xQogRMqQfBZaCeTHY7lCgU84RfyDenaUNNd94qbtKJKXRw7DljVq7DOg-9Y4KjwVqBzFVb3mZpKMzF99iZUaUwz5BbGJT9KT0vDyQuRuWCiQpGKvPLm1nAqz0s_f2CfExukyl3tFvXLkYpEwM7IDfw3h1WZ1VOaRxT8qhlBwdSanzH4eKA2jALDoQjzOJxvIfixNXxhKzPGidypcz-5GKcogqhZnEnszkU376KnxAYwSoGjYxXNtBdgrs_LKfkol3-j-JhfL9YP7WZPll-6ua1kGtFXbgA9sQBBvN39iZamJVbvUhyiS1rn7pIvsucxc0bvqCqT11BukDOQQi5BQuGIHNtO0F9z0GhT_Yznax8j2do31q7m6RGGnlYfINde_5LXT3L-q2b3T6h1Ej9jyvFO6R9LUeBo48cvg58dI2lZQ/file [following]\n",
            "--2023-02-03 09:26:38--  https://uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com/cd/0/inline2/B1xQogRMqQfBZaCeTHY7lCgU84RfyDenaUNNd94qbtKJKXRw7DljVq7DOg-9Y4KjwVqBzFVb3mZpKMzF99iZUaUwz5BbGJT9KT0vDyQuRuWCiQpGKvPLm1nAqz0s_f2CfExukyl3tFvXLkYpEwM7IDfw3h1WZ1VOaRxT8qhlBwdSanzH4eKA2jALDoQjzOJxvIfixNXxhKzPGidypcz-5GKcogqhZnEnszkU376KnxAYwSoGjYxXNtBdgrs_LKfkol3-j-JhfL9YP7WZPll-6ua1kGtFXbgA9sQBBvN39iZamJVbvUhyiS1rn7pIvsucxc0bvqCqT11BukDOQQi5BQuGIHNtO0F9z0GhT_Yznax8j2do31q7m6RGGnlYfINde_5LXT3L-q2b3T6h1Ej9jyvFO6R9LUeBo48cvg58dI2lZQ/file\n",
            "Reusing existing connection to uc26d5305c6ed76be4a6d6b17530.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 345582080 (330M) [application/octet-stream]\n",
            "Saving to: ‘reference_model.tar.gz’\n",
            "\n",
            "reference_model.tar 100%[===================>] 329.57M  6.86MB/s    in 34s     \n",
            "\n",
            "2023-02-03 09:27:13 (9.66 MB/s) - ‘reference_model.tar.gz’ saved [345582080/345582080]\n",
            "\n",
            "extracting from tar...\n",
            "reference_model/\n",
            "reference_model/model-000100000.pth\n",
            "deleting the tar...\n",
            "removed 'reference_model.tar.gz'\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading directory with data frames to generate training data from"
      ],
      "metadata": {
        "id": "R9V-6CiZvycm"
      },
      "id": "R9V-6CiZvycm"
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"frames\" # specify the name of the data folder located in drive\n",
        "!unzip -d \"$DATA_DIR\"/ /content/drive/MyDrive/\"$DATA_DIR\".zip # unziping frames"
      ],
      "metadata": {
        "id": "lLBW0C-an9sl"
      },
      "id": "lLBW0C-an9sl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating training data"
      ],
      "metadata": {
        "id": "qBTvq9aKwUkL"
      },
      "id": "qBTvq9aKwUkL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PIPs implementation"
      ],
      "metadata": {
        "id": "Rp5xw41PJcEu"
      },
      "id": "Rp5xw41PJcEu"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_weights):\n",
        "  model = Pips(stride=4).cuda()\n",
        "  parameters = list(model.parameters())\n",
        "  _ = saverloader.load(model_weights, model)\n",
        "  global_step = 0\n",
        "  model.eval()\n",
        "  return model\n",
        "\n",
        "\n",
        "def run_model(model, rgbs, N, split):\n",
        "    rgbs = rgbs.cuda().float() # B, S, C, H, W\n",
        "\n",
        "    B, S, C, H, W = rgbs.shape\n",
        "    rgbs_ = rgbs.reshape(B*S, C, H, W)\n",
        "    H_, W_ = 360, 640\n",
        "    rgbs_ = F.interpolate(rgbs_, (H_, W_), mode='bilinear')\n",
        "    H, W = H_, W_\n",
        "    rgbs = rgbs_.reshape(B, S, C, H, W)\n",
        "\n",
        "    # pick N points to track; we'll use a uniform grid\n",
        "    N_ = np.sqrt(N).round().astype(np.int32)\n",
        "    grid_y, grid_x = utils.basic.meshgrid2d(B, N_, N_, stack=False, norm=False, device='cuda')\n",
        "    grid_y = 8 + grid_y.reshape(B, -1)/float(N_-1) * (H-16)\n",
        "    grid_x = 8 + grid_x.reshape(B, -1)/float(N_-1) * (W-16)\n",
        "    xy = torch.stack([grid_x, grid_y], dim=-1) # B, N_*N_, 2\n",
        "    _, S, C, H, W = rgbs.shape\n",
        "\n",
        "    print_stats('rgbs', rgbs)\n",
        "\n",
        "    # splitting grid of points into tensors of size 1500 along dim=1\n",
        "    if split:\n",
        "       xy_split = torch.split(xy, 1500, dim=1)\n",
        "       preds_split = []\n",
        "       vis_split = []\n",
        "\n",
        "      # for each splitted point compute trajs\n",
        "       for i in range(len(xy_split)):\n",
        "         preds, preds_anim, vis, stats = model(xy_split[i], rgbs, iters=6)\n",
        "         preds_split.append(preds[-1])\n",
        "         vis_split.append(vis[-1])\n",
        "\n",
        "       # put trajs back together\n",
        "       trajs_e = torch.cat(preds_split, 2)\n",
        "       vis_e = torch.cat(vis_split, 1).unsqueeze(0)\n",
        "       \n",
        "\n",
        "    else:\n",
        "      preds, preds_anim, vis, stats = model(xy, rgbs, iters=6)\n",
        "      # preds is a list of torch tensors \n",
        "      trajs_e = preds[-1] # tensor of shape (frames, tracking points, 2)\n",
        "      vis_e = vis\n",
        "\n",
        "    print_stats('vis_e', vis_e)\n",
        "    return trajs_e[:,-1,:,:], vis_e[:,-1,:]\n",
        "\n",
        "def generate_training_data(pips_model, video_name, n, split=True):\n",
        "    model = pips_model\n",
        "    \n",
        "    ## Choose hyps\n",
        "    B = 1\n",
        "    S = 8\n",
        "    N = n**2 # number of points to track\n",
        "\n",
        "    # Get frames of a file\n",
        "    filenames = glob.glob(DATA_DIR+'/content/frames/'+video_name+'/frames/*.jpg')\n",
        "    filenames = sorted(filenames)\n",
        "\n",
        "    # Remove every second frame from a list\n",
        "    n = 2\n",
        "    del filenames[n - 1::n]\n",
        "\n",
        "    max_iters = len(filenames)//S # run each unique subsequence\n",
        "    iters = 100\n",
        "    global_step = 0\n",
        "\n",
        "    # Run model each of 8 frames\n",
        "    while global_step < iters:\n",
        "        global_step += 1\n",
        "\n",
        "        if (global_step < 100) or (global_step>(max_iters-100)):\n",
        "          continue\n",
        "        \n",
        "        try:\n",
        "            rgbs = []\n",
        "            sample_id = video_name[-11:]+\"_\"+str((global_step-1)*S)\n",
        "            print(\"sample {}: step {}/{}\".format(sample_id, global_step, max_iters))\n",
        "\n",
        "            # skip generating this sample if already in the log list\n",
        "            if sample_id in LOG_LIST:\n",
        "                  print(sample_id+\" already in log list\")\n",
        "                  continue\n",
        "            for s in range(S):\n",
        "                frame_num = (global_step-1)*S+s\n",
        "                fn = filenames[frame_num]\n",
        "                if s==0:\n",
        "                    print('start frame', fn)\n",
        "                im = imageio.imread(fn)\n",
        "                im = im.astype(np.uint8)\n",
        "                im = torch.from_numpy(im).permute(2,0,1)\n",
        "                rgbs.append(im)\n",
        "            rgbs = torch.stack(rgbs, dim=0).unsqueeze(0) # 1, S, C, H, W\n",
        "\n",
        "            with torch.no_grad():\n",
        "                trajs_e, vis_e = run_model(model, rgbs, N, split)\n",
        "\n",
        "            # store img0 and img1 (frame 1 and 8) and trajs_e, vis_e\n",
        "            save_data(sample_id, rgbs[0][0], rgbs[0][1], rgbs[0][3], rgbs[0][-1], trajs_e, vis_e)\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print('error', e)\n",
        "\n",
        "def img_to_array(tensor_img):\n",
        "   x = tensor_img.permute(1, 2, 0).numpy() # from tensor to numpy array\n",
        "   x = cv2.resize(x, (240, 120)) # resizing image\n",
        "   return x\n",
        "\n",
        "def save_data(sample_id, frame0, frame1, frame3, frame7, trajs, vis):\n",
        "  \"\"\"\n",
        "  Saving\n",
        "  - coordinates to COORDS_DIR as .npy files\n",
        "  - visibility of coordinates to VIS_DIR as .npy files\n",
        "  - 0th frames to FRAME0_DIR directory as .npy files\n",
        "  - 7th frames to FRAME7_DIR directory as .npy files\n",
        "  \n",
        "  - Coordinates, visibility and frames are mapped with sample_id, all sample_ids are stored in sample_ids.txt\n",
        "  \"\"\"\n",
        "  img0 = img_to_array(frame0) # transform 1st frame to array\n",
        "  img1 = img_to_array(frame1) # transform 2nd frame to array\n",
        "  img3 = img_to_array(frame3) # transform 2nd frame to array\n",
        "  img7 = img_to_array(frame7) # tranform last frame (8th) to array\n",
        "  coords = trajs.cpu().numpy()\n",
        "  vis = vis.cpu().numpy()\n",
        "\n",
        "  # Store coords, frame0, frame1\n",
        "  np.save(COORDS_DIR+sample_id, coords)\n",
        "  np.save(VIS_DIR+sample_id, vis)\n",
        "  np.save(FRAME0_DIR+sample_id, img0)\n",
        "  np.save(FRAME1_DIR+sample_id, img1)\n",
        "  np.save(FRAME3_DIR+sample_id, img3)\n",
        "  np.save(FRAME7_DIR+sample_id, img7)\n",
        "\n",
        "  # Add sample_id to log list\n",
        "  LOG_LIST.append(sample_id)\n",
        "  save_log(LOG_LIST)\n",
        "\n",
        "def save_log(log_list):\n",
        "  with open(LOG_FILE, \"w\") as outfile:\n",
        "    outfile.write(\"\\n\".join(log_list))"
      ],
      "metadata": {
        "id": "jWzwnNKZKFyj"
      },
      "id": "jWzwnNKZKFyj",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('reference_model')"
      ],
      "metadata": {
        "id": "LTZQnKzeKl6r",
        "outputId": "f6238502-1e62-4d4e-9118-8b4314ae8a9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LTZQnKzeKl6r",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading ckpt from reference_model\n",
            "...found checkpoint reference_model/model-000100000.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating directories and running generation of data"
      ],
      "metadata": {
        "id": "YYg8VkJJJh0P"
      },
      "id": "YYg8VkJJJh0P"
    },
    {
      "cell_type": "code",
      "source": [
        "# create a folder to store training data in\n",
        "!rm -r training_data\n",
        "!mkdir training_data\n",
        "!mkdir training_data/frame0/\n",
        "!mkdir training_data/frame1/\n",
        "!mkdir training_data/frame3/\n",
        "!mkdir training_data/frame7/\n",
        "!mkdir training_data/coords/\n",
        "!mkdir training_data/vis/\n",
        "!touch training_data/sample_ids.txt\n",
        "PATH = \"\""
      ],
      "metadata": {
        "id": "4cZ_q9I6tBNj"
      },
      "id": "4cZ_q9I6tBNj",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want to use an old training data folder\n",
        "# cp from drive to colab memory and unzip\n",
        "TRAIN_DATA_DIR = \"training_data_14122022\" # specify the name of the data folder located in drive\n",
        "!unzip -d \"$TRAIN_DATA_DIR\"/ /content/drive/MyDrive/\"$TRAIN_DATA_DIR\".zip # unziping frames\n",
        "PATH = TRAIN_DATA_DIR+\"/content/\""
      ],
      "metadata": {
        "id": "tApdIoeTvoDg"
      },
      "id": "tApdIoeTvoDg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANING_DATA_DIR = PATH+\"training_data/\"\n",
        "COORDS_DIR = PATH+\"training_data/coords/\"\n",
        "VIS_DIR = PATH+\"training_data/vis/\"\n",
        "FRAME0_DIR= PATH+\"training_data/frame0/\"\n",
        "FRAME1_DIR= PATH+\"training_data/frame1/\"\n",
        "FRAME3_DIR= PATH+\"training_data/frame3/\"\n",
        "FRAME7_DIR= PATH+\"training_data/frame7/\"\n",
        "LOG_FILE = PATH+\"training_data/sample_ids.txt\"\n",
        "LOG_LIST = open(LOG_FILE).read().splitlines()"
      ],
      "metadata": {
        "id": "lyp0MVe7uWwf"
      },
      "id": "lyp0MVe7uWwf",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_training_data(model, 'Tai chiKunlun Si Xiang Quan Demonstrated by Huang Shuanqing--CR4xjdQbkc', n=64)\n",
        "# generate_training_data(model, 'Tai chi陈式太极拳五十六式-vB8XTJfV4rY', n=64)"
      ],
      "metadata": {
        "id": "HNvo9dPWXfmz",
        "outputId": "37dd8879-93f5-478a-81c4-a11e0f7880c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HNvo9dPWXfmz",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample -CR4xjdQbkc_792: step 100/403\n",
            "start frame frames/content/frames/Tai chiKunlun Si Xiang Quan Demonstrated by Huang Shuanqing--CR4xjdQbkc/frames/frame_01585.jpg\n",
            "rgbs (float32) min = 0.00, mean = 169.58, max = 255.00 torch.Size([1, 8, 3, 360, 640])\n",
            "vis_e (float32) min = -6.82, mean = 6.42, max = 12.08 torch.Size([1, 8, 4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_training_data(model, 'Tai chiOld Frame Wǔ Family Taiji Quan,Rare Exercises and Tui Shou-Sh2siPvCPo0', n=64)\n",
        "generate_training_data(model, 'Tai chiKunlun Si Xiang Quan Demonstrated by Huang Shuanqing--CR4xjdQbkc', n=64)\n",
        "generate_training_data(model, 'Tai chiSun Style Tai Ji Quan - Xing Yi Sword form-S9MN1i6Fejc', n=64)\n",
        "generate_training_data(model, 'Tai chi世界太極拳冠軍,邱慧芳示範,太極拳16武-fL8f6X3JPzE', n=64)\n",
        "generate_training_data(model, 'Tai chiYang Taijiquan 16 vorm-KjMxdYJOwqI', n=64)\n",
        "generate_training_data(model, 'Tai chiTrần thức giản hóa do Vs - Thiều Ngọc Sơn diễn luyện.-MGYF1aDwUKg', n=64)\n",
        "generate_training_data(model, 'Tai chiJin Gang Kwan Dao-3zIcD0hIpfc', n=64)\n",
        "generate_training_data(model, 'Tai chi武当丹剑.flv-42PJ4MlxWKA', n=64)\n",
        "generate_training_data(model, 'Tai chiWudang Taichi 18 Xuanwu Style 武当18式太極拳（玄武派） Master Xu Gu 虚谷师父-Mo87mOAnAio', n=64)\n",
        "generate_training_data(model, 'Tai chiTai Chi 32 Yang Stil Schwertform  _ 32 Step Yang Style Tai Chi Sword Routine-asL3ZyuNeB0', n=64)"
      ],
      "metadata": {
        "id": "lkF4vYMA7zvM"
      },
      "id": "lkF4vYMA7zvM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_training_data(model, 'Tai chiДаосский тайцзицюань школы Лун Мэнь Первая форма 1-й Раздел Ли Фа Цзюнь-8DemshD_8a4', n=64)\n",
        "generate_training_data(model, 'Tai chiWuDang Tai Ji 28  二十八式 2009拍.flv-BtuIV3k5O6Q', n=64)\n",
        "generate_training_data(model, 'Tai chi吳式太極快架-KMO1BluPtU4', n=64)\n",
        "generate_training_data(model, 'Tai chiWudang Taijiquan Forms - Cheng Tinhung (鄭天熊) lineage-zxsGZCdT7Ns', n=64)\n",
        "generate_training_data(model, 'Tai chiTai Chi sword form-sm6-dbG5Rho', n=64)\n",
        "generate_training_data(model, 'Tai chizhaobao Taichi 24 刘钢 示范 武当赵堡和式太极拳二十四式简化太极拳-FmJ33H476pI', n=64)\n",
        "generate_training_data(model, 'Tai chi陈式太极拳五十六式-vB8XTJfV4rY', n=64)\n",
        "generate_training_data(model, 'Tai chi64 式太極拳練習（第一段），090927。-K7td6IVvS8w', n=64)\n",
        "generate_training_data(model, 'Tai chi56式夕陽美功夫扇-uOw-z7CR7x8', n=64)\n",
        "generate_training_data(model, 'Tai chiTai Chi for Osteoporosis Front Demo-AUzpWyGi8Gw', n=64)"
      ],
      "metadata": {
        "id": "fe0F1vzcEjrW"
      },
      "id": "fe0F1vzcEjrW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_training_data(model, 'Tai chichen 56-l0aKiGrTUGw', n=64)\n",
        "generate_training_data(model, 'Tai chi陳氏太極拳：老架一路(上)王西安.flv-CA9-8CydW4A', n=64)\n",
        "generate_training_data(model, 'Tai chiTaijiquan Tai Chi Pai Lin part 2-6f6nS3PCeQM', n=64)"
      ],
      "metadata": {
        "id": "Q6LcogurFEzY"
      },
      "id": "Q6LcogurFEzY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of file names to go through\n",
        "videos_list = [f for f in os.listdir(DATA_DIR+'/content/frames/') if not f.startswith('.')]\n",
        "print(videos_list)"
      ],
      "metadata": {
        "id": "_DmrwfqCnJVH"
      },
      "id": "_DmrwfqCnJVH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through the videos list and generate training data files\n",
        "for x in range(len(videos_list)):\n",
        "  print(\"Now generating training data for {}, {} out of {}.\".format(videos_list[x], x, len(videos_list)))\n",
        "  generate_training_data(model, videos_list[x], 100)"
      ],
      "metadata": {
        "id": "6H_eyv85wZd3"
      },
      "id": "6H_eyv85wZd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zip data and store in Drive"
      ],
      "metadata": {
        "id": "y7K9XdyxJwAc"
      },
      "id": "y7K9XdyxJwAc"
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "TODAY = date.today()\n",
        "\n",
        "# zip training data\n",
        "!cd /content/\"$PATH\"training_data && zip -r /content/training_data_1_2frames\"$TODAY\".zip .\n",
        "# cp NumPy zip file into drive\n",
        "!cp training_data_1_2frames\"$TODAY\".zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "PH9XF70MulWV",
        "outputId": "6d5f407e-3e21-450a-a08c-20fdfa590b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PH9XF70MulWV",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: vis/ (stored 0%)\n",
            "  adding: vis/-CR4xjdQbkc_792.npy (deflated 12%)\n",
            "  adding: frame0/ (stored 0%)\n",
            "  adding: frame0/-CR4xjdQbkc_792.npy (deflated 45%)\n",
            "  adding: sample_ids.txt (stored 0%)\n",
            "  adding: frame7/ (stored 0%)\n",
            "  adding: frame7/-CR4xjdQbkc_792.npy (deflated 45%)\n",
            "  adding: frame3/ (stored 0%)\n",
            "  adding: frame3/-CR4xjdQbkc_792.npy (deflated 46%)\n",
            "  adding: coords/ (stored 0%)\n",
            "  adding: coords/-CR4xjdQbkc_792.npy (deflated 11%)\n",
            "  adding: frame1/ (stored 0%)\n",
            "  adding: frame1/-CR4xjdQbkc_792.npy (deflated 44%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}