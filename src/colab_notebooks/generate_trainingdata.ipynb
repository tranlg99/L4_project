{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "239cca92",
      "metadata": {
        "id": "239cca92"
      },
      "outputs": [],
      "source": [
        "# connecting drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing requirements\n",
        "!pip install imageio==2.19.3\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install tensorboardX==2.2\n",
        "!pip install einops==0.4.1\n",
        "!pip install scikit-learn==1.1.1\n",
        "!pip install matplotlib==3.5.1\n",
        "!pip install protobuf==3.20.0\n",
        "!pip install fire==0.4.0\n",
        "!pip install moviepy==1.0.3"
      ],
      "metadata": {
        "id": "daqRwkpfAq6L"
      },
      "id": "daqRwkpfAq6L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/drive_folder/pips/')\n",
        "import time\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import saverloader\n",
        "import imageio as imageio\n",
        "from nets.pips import Pips\n",
        "import utils.improc\n",
        "import random\n",
        "import glob\n",
        "from utils.basic import print_, print_stats\n",
        "import torch\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# save numpy array as npz file\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed"
      ],
      "metadata": {
        "id": "O_R-IzS1EPcy"
      },
      "id": "O_R-IzS1EPcy",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_weights):\n",
        "  model = Pips(stride=4).cuda()\n",
        "  parameters = list(model.parameters())\n",
        "  _ = saverloader.load(model_weights, model)\n",
        "  global_step = 0\n",
        "  model.eval()\n",
        "  return model"
      ],
      "metadata": {
        "id": "jWzwnNKZKFyj"
      },
      "id": "jWzwnNKZKFyj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random.seed(125)\n",
        "# np.random.seed(125)\n",
        "\n",
        "def run_model(model, rgbs, N):\n",
        "    rgbs = rgbs.cuda().float() # B, S, C, H, W\n",
        "\n",
        "    B, S, C, H, W = rgbs.shape\n",
        "    rgbs_ = rgbs.reshape(B*S, C, H, W)\n",
        "    H_, W_ = 360, 640\n",
        "    rgbs_ = F.interpolate(rgbs_, (H_, W_), mode='bilinear')\n",
        "    H, W = H_, W_\n",
        "    rgbs = rgbs_.reshape(B, S, C, H, W)\n",
        "\n",
        "    # pick N points to track; we'll use a uniform grid\n",
        "    N_ = np.sqrt(N).round().astype(np.int32)\n",
        "    grid_y, grid_x = utils.basic.meshgrid2d(B, N_, N_, stack=False, norm=False, device='cuda')\n",
        "    grid_y = 8 + grid_y.reshape(B, -1)/float(N_-1) * (H-16)\n",
        "    grid_x = 8 + grid_x.reshape(B, -1)/float(N_-1) * (W-16)\n",
        "    xy = torch.stack([grid_x, grid_y], dim=-1) # B, N_*N_, 2\n",
        "    _, S, C, H, W = rgbs.shape\n",
        "\n",
        "    print_stats('rgbs', rgbs)\n",
        "    preds, preds_anim, vis_e, stats = model(xy, rgbs, iters=6)\n",
        "    trajs_e = preds[-1]\n",
        "    print_stats('trajs_e', trajs_e)\n",
        "    \n",
        "    pad = 50\n",
        "    rgbs = F.pad(rgbs.reshape(B*S, 3, H, W), (pad, pad, pad, pad), 'constant', 0).reshape(B, S, 3, H+pad*2, W+pad*2)\n",
        "    trajs_e = trajs_e + pad\n",
        "    \n",
        "    # if sw is not None and sw.save_this:\n",
        "    #     linewidth = 2\n",
        "\n",
        "    #     # visualize the input\n",
        "    #     o1 = sw.summ_rgbs('inputs/rgbs', utils.improc.preprocess_color(rgbs[0:1]).unbind(1))\n",
        "    #     # visualize the trajs overlaid on the rgbs\n",
        "    #     o2 = sw.summ_traj2ds_on_rgbs('outputs/trajs_on_rgbs', trajs_e[0:1], utils.improc.preprocess_color(rgbs[0:1]), cmap='spring', linewidth=linewidth)\n",
        "    #     # visualize the trajs alone\n",
        "    #     o3 = sw.summ_traj2ds_on_rgbs('outputs/trajs_on_black', trajs_e[0:1], torch.ones_like(rgbs[0:1])*-0.5, cmap='spring', linewidth=linewidth)\n",
        "    #     # concat these for a synced wide vis\n",
        "    #     wide_cat = torch.cat([o1, o2, o3], dim=-1)\n",
        "    #     sw.summ_rgbs('outputs/wide_cat', wide_cat.unbind(1))\n",
        "\n",
        "    #     # write to disk, in case that's more convenient\n",
        "    #     wide_list = list(wide_cat.unbind(1))\n",
        "    #     wide_list = [wide[0].permute(1,2,0).cpu().numpy() for wide in wide_list]\n",
        "    #     wide_list = [Image.fromarray(wide) for wide in wide_list]\n",
        "    #     out_fn = './out_%d.gif' % sw.global_step\n",
        "    #     wide_list[0].save(out_fn, save_all=True, append_images=wide_list[1:])\n",
        "    #     print('saved %s' % out_fn)\n",
        "\n",
        "    #     # alternate vis\n",
        "    #     sw.summ_traj2ds_on_rgbs2('outputs/trajs_on_rgbs2', trajs_e[0:1], vis_e[0:1], utils.improc.preprocess_color(rgbs[0:1]))\n",
        "        \n",
        "    #     # animation of inference iterations\n",
        "    #     rgb_vis = []\n",
        "    #     for trajs_e_ in preds_anim:\n",
        "    #         trajs_e_ = trajs_e_ + pad\n",
        "    #         rgb_vis.append(sw.summ_traj2ds_on_rgb('', trajs_e_[0:1], torch.mean(utils.improc.preprocess_color(rgbs[0:1]), dim=1), cmap='spring', linewidth=linewidth, only_return=True))\n",
        "    #     sw.summ_rgbs('outputs/animated_trajs_on_rgb', rgb_vis)\n",
        "\n",
        "# return vis??\n",
        "    return trajs_e-pad"
      ],
      "metadata": {
        "id": "rw1p5vpiE6l-"
      },
      "id": "rw1p5vpiE6l-",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(pips_model, video_name):\n",
        "    ## choose hyps\n",
        "    B = 1\n",
        "    S = 8\n",
        "    N = 2**2 # number of points to track\n",
        "\n",
        "    filenames = glob.glob('data_small/content/frames/'+video_name+'/frames/*_001*.jpg')\n",
        "    filenames = sorted(filenames)\n",
        "    max_iters = len(filenames)//S # run each unique subsequence\n",
        "\n",
        "    model = pips_model\n",
        "\n",
        "    global_step = 0\n",
        "    print(global_step)\n",
        "    print(max_iters)\n",
        "\n",
        "    a = np.empty([1,2])\n",
        "\n",
        "    while global_step < max_iters:\n",
        "        \n",
        "        global_step += 1\n",
        "\n",
        "        try:\n",
        "            rgbs = []\n",
        "            for s in range(S):\n",
        "                fn = filenames[(global_step-1)*S+s]\n",
        "                if s==0:\n",
        "                    print('start frame', fn)\n",
        "                im = imageio.imread(fn)\n",
        "                im = im.astype(np.uint8)\n",
        "                rgbs.append(torch.from_numpy(im).permute(2,0,1))\n",
        "            rgbs = torch.stack(rgbs, dim=0).unsqueeze(0) # 1, S, C, H, W\n",
        "\n",
        "            with torch.no_grad():\n",
        "                \n",
        "                trajs_e = run_model(model, rgbs, N)\n",
        "\n",
        "            # store training_img and trajs_e\n",
        "            rgb_array = rgbs[0][0].permute(1, 2, 0).numpy() # from tensor to numpy array\n",
        "            training_img = cv2.resize(rgb_array , (360, 640)) # resizing image\n",
        "            trajs_array = trajs_e.cpu().numpy()\n",
        "            print(trajs_array[0][-1].shape)\n",
        "\n",
        "            # define data\n",
        "            if global_step ==1:\n",
        "              a = np.array([(rgb_array, trajs_array[0][-1])])\n",
        "            else:\n",
        "              a=np.append(a, [(rgb_array, trajs_array[0][-1])],axis = 0)\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print('error', e)\n",
        "\n",
        "    # save to npy file\n",
        "    savez_compressed(video_name+'.npz', a)\n"
      ],
      "metadata": {
        "id": "MZn_pJbKIV_l"
      },
      "id": "MZn_pJbKIV_l",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading their reference model\n",
        "!bash /content/drive/MyDrive/drive_folder/pips/get_reference_model.sh"
      ],
      "metadata": {
        "id": "VngwyXNrAuQd"
      },
      "id": "VngwyXNrAuQd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('reference_model')"
      ],
      "metadata": {
        "id": "LTZQnKzeKl6r",
        "outputId": "98527d97-54f3-42c0-9795-c9674fe2c635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LTZQnKzeKl6r",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading ckpt from reference_model\n",
            "...found checkpoint reference_model/model-000100000.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unziping frames into data folder\n",
        "!unzip /content/drive/MyDrive/frames_small.zip -d data_small"
      ],
      "metadata": {
        "id": "pBG51Q0rCBRe",
        "outputId": "15284c47-c735-4970-ce87-160597ac1095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pBG51Q0rCBRe",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/frames_small.zip\n",
            "replace data_small/content/frames/Tai chi56式夕陽美功夫扇-uOw-z7CR7x8/frames/frame_06296.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tempfile import TemporaryFile\n",
        "# create folder for numpy files\n",
        "\n",
        "\n",
        "# for video_name in  os.listdir(\"data_small/content/frames\"):\n",
        "  # outfile = TemporaryFile() # create a np file\n",
        "  # x = np.array() # create array\n",
        "\n",
        "  # np.save(outfile, x) # save numpy file "
      ],
      "metadata": {
        "id": "dDhyu9SPG6TL"
      },
      "id": "dDhyu9SPG6TL",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_training_data(model,\"Tai chiRen Guang Yi - Chen Style Taiji silk reeling part II-Wh3AmDsdQtM\")"
      ],
      "metadata": {
        "id": "6H_eyv85wZd3"
      },
      "id": "6H_eyv85wZd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "\n",
        "data = load('Tai chiRen Guang Yi - Chen Style Taiji silk reeling part II-Wh3AmDsdQtM.npz', allow_pickle=True)\n",
        "lst = data.files\n",
        "for item in lst:\n",
        "  for x in range(len(item)):\n",
        "    plt.imshow(data[item][x][0])\n",
        "    plt.show()\n",
        "    print(data[item][x][1])"
      ],
      "metadata": {
        "id": "ZAJ1hanTBl2C"
      },
      "id": "ZAJ1hanTBl2C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "# zip all numpy files\n",
        "# cp NumPy zip file into drive"
      ],
      "metadata": {
        "id": "PH9XF70MulWV"
      },
      "id": "PH9XF70MulWV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}