{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Script for Generating Training Data from Frames using PIPs\n",
        "https://github.com/aharley/pips"
      ],
      "metadata": {
        "id": "7aDztnqsvgfZ"
      },
      "id": "7aDztnqsvgfZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial set up\n",
        "Connection to MyDrive, requirements, imports, downloading models weights"
      ],
      "metadata": {
        "id": "II3QRFFivngi"
      },
      "id": "II3QRFFivngi"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "239cca92",
      "metadata": {
        "id": "239cca92",
        "outputId": "401d3171-bbaf-454c-e5e8-d5da855e0e56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connecting drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing requirements\n",
        "!pip install imageio==2.19.3\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install einops==0.4.1\n",
        "!pip install scikit-learn==1.1.1\n",
        "!pip install matplotlib==3.5.1\n",
        "!pip install protobuf==3.20.0\n",
        "!pip install fire==0.4.0"
      ],
      "metadata": {
        "id": "daqRwkpfAq6L",
        "outputId": "155c9a02-92a6-4907-a29f-af7db8542d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "daqRwkpfAq6L",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio==2.19.3\n",
            "  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 15.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from imageio==2.19.3) (1.21.6)\n",
            "Collecting pillow>=8.3.2\n",
            "  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 57.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: pillow, imageio\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.9.0\n",
            "    Uninstalling imageio-2.9.0:\n",
            "      Successfully uninstalled imageio-2.9.0\n",
            "Successfully installed imageio-2.19.3 pillow-9.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python==4.6.0.66 in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python==4.6.0.66) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops==0.4.1\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==1.1.1\n",
            "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (1.21.6)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn==1.1.1) (1.2.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "Successfully installed scikit-learn-1.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting matplotlib==3.5.1\n",
            "  Downloading matplotlib-3.5.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (9.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (1.21.6)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.1) (1.4.4)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1) (1.15.0)\n",
            "Installing collected packages: fonttools, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "Successfully installed fonttools-4.38.0 matplotlib-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting protobuf==3.20.0\n",
            "  Downloading protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 15.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.57.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.7.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.16.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\n",
            "Successfully installed protobuf-3.20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fire==0.4.0\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire==0.4.0) (2.1.1)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=3b07f63c9a0e679f7678729895268d41c59347eeb5ddc513c650b64950c70908\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
            "Successfully built fire\n",
            "Installing collected packages: fire\n",
            "Successfully installed fire-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/drive_folder/pips')\n",
        "import time\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import saverloader\n",
        "from nets.pips import Pips\n",
        "import utils.improc\n",
        "import random\n",
        "import glob\n",
        "from utils.basic import print_, print_stats\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import imageio.v2 as imageio\n",
        "from csv import writer\n",
        "\n",
        "# save numpy array as npz file\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed"
      ],
      "metadata": {
        "id": "O_R-IzS1EPcy"
      },
      "id": "O_R-IzS1EPcy",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading their reference model\n",
        "!bash /content/drive/MyDrive/drive_folder/pips/get_reference_model.sh"
      ],
      "metadata": {
        "id": "VngwyXNrAuQd",
        "outputId": "50cc98e1-2d14-4225-acfc-fd1883a1ed59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VngwyXNrAuQd",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading the model from dropbox...\n",
            "--2023-01-01 10:47:37--  https://www.dropbox.com/s/hbo7ns4vfx1sejp/reference_model.tar.gz\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6026:18::a27d:4612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/hbo7ns4vfx1sejp/reference_model.tar.gz [following]\n",
            "--2023-01-01 10:47:37--  https://www.dropbox.com/s/raw/hbo7ns4vfx1sejp/reference_model.tar.gz\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com/cd/0/inline/BzuP7_gOyCGuv_jZ2EZNvozamWOOaRN_b5Loz6fLwj2qmTjRYpihm5y-ZMb2S-4IBCX0zkdjvz_N6iZwVs0kIDUlmwPNe1ueNanXBH0AWDkntFlo5FCkMdDRYdMKHmmUWmx0Yj361TwX42jJhqTKyBJ8iRjve6lfJOTsk5CeuBV_LQ/file# [following]\n",
            "--2023-01-01 10:47:38--  https://uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com/cd/0/inline/BzuP7_gOyCGuv_jZ2EZNvozamWOOaRN_b5Loz6fLwj2qmTjRYpihm5y-ZMb2S-4IBCX0zkdjvz_N6iZwVs0kIDUlmwPNe1ueNanXBH0AWDkntFlo5FCkMdDRYdMKHmmUWmx0Yj361TwX42jJhqTKyBJ8iRjve6lfJOTsk5CeuBV_LQ/file\n",
            "Resolving uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com (uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com (uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bzvn0i9LEQCMRLliVqIeE1hOvuYoWs3OUxSgD2ZnFEAMFEAtw_a6j4N_kwdGDhJk44L1OqRrwNIa9Sjr6O_AQESGzpiwC9VWfQbG6v1VKezTS8z9qNWLZmLEd_Ph9iwzOpOQuymgxdNjOf3hou_c0_tlde0fMOF80myKiKG15qaSJsiq2H73HLOYDCQcDRvsrcHVoLBizPMj4rX_dkBQyANHhCOqLjtEXz_sFaxxQY1i7dxhn87jTy91cVrQiKWo0PV2m7koGrhCOaYnG3GZURKvbV285as6CtOoJKOPFfeQBQVfBy60rREnJzYdD2t7SvWGIvMo2f9d0t5U_k8oV9J5Ci3HIkFtRnOlvlFbzftynABQ1QMK9L7TJ7Te2vl2UAPK-4GB1KZ6ikxVHoQO2YrUWani4QdZaG7SoRWyqay2hg/file [following]\n",
            "--2023-01-01 10:47:38--  https://uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com/cd/0/inline2/Bzvn0i9LEQCMRLliVqIeE1hOvuYoWs3OUxSgD2ZnFEAMFEAtw_a6j4N_kwdGDhJk44L1OqRrwNIa9Sjr6O_AQESGzpiwC9VWfQbG6v1VKezTS8z9qNWLZmLEd_Ph9iwzOpOQuymgxdNjOf3hou_c0_tlde0fMOF80myKiKG15qaSJsiq2H73HLOYDCQcDRvsrcHVoLBizPMj4rX_dkBQyANHhCOqLjtEXz_sFaxxQY1i7dxhn87jTy91cVrQiKWo0PV2m7koGrhCOaYnG3GZURKvbV285as6CtOoJKOPFfeQBQVfBy60rREnJzYdD2t7SvWGIvMo2f9d0t5U_k8oV9J5Ci3HIkFtRnOlvlFbzftynABQ1QMK9L7TJ7Te2vl2UAPK-4GB1KZ6ikxVHoQO2YrUWani4QdZaG7SoRWyqay2hg/file\n",
            "Reusing existing connection to uc654b015fc500ae7887c23192eb.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 345582080 (330M) [application/octet-stream]\n",
            "Saving to: ‘reference_model.tar.gz’\n",
            "\n",
            "reference_model.tar 100%[===================>] 329.57M  21.9MB/s    in 16s     \n",
            "\n",
            "2023-01-01 10:47:54 (21.2 MB/s) - ‘reference_model.tar.gz’ saved [345582080/345582080]\n",
            "\n",
            "extracting from tar...\n",
            "reference_model/\n",
            "reference_model/model-000100000.pth\n",
            "deleting the tar...\n",
            "removed 'reference_model.tar.gz'\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading directory with data frames to generate training data from"
      ],
      "metadata": {
        "id": "R9V-6CiZvycm"
      },
      "id": "R9V-6CiZvycm"
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"frames\" # specify the name of the data folder located in drive\n",
        "!unzip -d \"$DATA_DIR\"/ /content/drive/MyDrive/\"$DATA_DIR\".zip # unziping frames"
      ],
      "metadata": {
        "id": "lLBW0C-an9sl"
      },
      "id": "lLBW0C-an9sl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating training data"
      ],
      "metadata": {
        "id": "qBTvq9aKwUkL"
      },
      "id": "qBTvq9aKwUkL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PIPs implementation"
      ],
      "metadata": {
        "id": "Rp5xw41PJcEu"
      },
      "id": "Rp5xw41PJcEu"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_weights):\n",
        "  model = Pips(stride=4).cuda()\n",
        "  parameters = list(model.parameters())\n",
        "  _ = saverloader.load(model_weights, model)\n",
        "  global_step = 0\n",
        "  model.eval()\n",
        "  return model\n",
        "\n",
        "\n",
        "def run_model(model, rgbs, N, split):\n",
        "    rgbs = rgbs.cuda().float() # B, S, C, H, W\n",
        "\n",
        "    B, S, C, H, W = rgbs.shape\n",
        "    rgbs_ = rgbs.reshape(B*S, C, H, W)\n",
        "    H_, W_ = 360, 640\n",
        "    rgbs_ = F.interpolate(rgbs_, (H_, W_), mode='bilinear')\n",
        "    H, W = H_, W_\n",
        "    rgbs = rgbs_.reshape(B, S, C, H, W)\n",
        "\n",
        "    # pick N points to track; we'll use a uniform grid\n",
        "    N_ = np.sqrt(N).round().astype(np.int32)\n",
        "    grid_y, grid_x = utils.basic.meshgrid2d(B, N_, N_, stack=False, norm=False, device='cuda')\n",
        "    grid_y = 8 + grid_y.reshape(B, -1)/float(N_-1) * (H-16)\n",
        "    grid_x = 8 + grid_x.reshape(B, -1)/float(N_-1) * (W-16)\n",
        "    xy = torch.stack([grid_x, grid_y], dim=-1) # B, N_*N_, 2\n",
        "    _, S, C, H, W = rgbs.shape\n",
        "\n",
        "    print_stats('rgbs', rgbs)\n",
        "\n",
        "    # splitting grid of points into tensors of size 1500 along dim=1\n",
        "    if split:\n",
        "       xy_split = torch.split(xy, 1500, dim=1)\n",
        "       preds_split = []\n",
        "       vis_split = []\n",
        "\n",
        "      # for each splitted point compute trajs\n",
        "       for i in range(len(xy_split)):\n",
        "         preds, preds_anim, vis, stats = model(xy_split[i], rgbs, iters=6)\n",
        "         preds_split.append(preds[-1])\n",
        "         vis_split.append(vis[-1])\n",
        "\n",
        "       # put trajs back together\n",
        "       trajs_e = torch.cat(preds_split, 2)\n",
        "       vis_e = torch.cat(vis_split, 1).unsqueeze(0)\n",
        "       \n",
        "\n",
        "    else:\n",
        "      preds, preds_anim, vis, stats = model(xy, rgbs, iters=6)\n",
        "      # preds is a list of torch tensors \n",
        "      trajs_e = preds[-1] # tensor of shape (frames, tracking points, 2)\n",
        "      vis_e = vis\n",
        "\n",
        "    print_stats('vis_e', vis_e)\n",
        "    return trajs_e[:,-1,:,:], vis_e[:,-1,:]\n",
        "\n",
        "def generate_training_data(pips_model, video_name, n, split=True):\n",
        "    model = pips_model\n",
        "    \n",
        "    ## Choose hyps\n",
        "    B = 1\n",
        "    S = 8\n",
        "    N = n**2 # number of points to track\n",
        "\n",
        "    # Get frames of a file\n",
        "    filenames = glob.glob(DATA_DIR+'/content/frames/'+video_name+'/frames/*.jpg')\n",
        "    filenames = sorted(filenames)\n",
        "\n",
        "    # Remove every second frame from a list\n",
        "    n = 2\n",
        "    del filenames[n - 1::n]\n",
        "\n",
        "    max_iters = len(filenames)//S # run each unique subsequence\n",
        "    iters = 2\n",
        "    global_step = 0\n",
        "\n",
        "    # Run model each of 8 frames\n",
        "    while global_step < iters:\n",
        "        global_step += 1\n",
        "        \n",
        "        try:\n",
        "            rgbs = []\n",
        "            sample_id = video_name[-11:]+\"_\"+str((global_step-1)*S)\n",
        "            print(\"sample {}: step {}/{}\".format(sample_id, global_step, max_iters))\n",
        "\n",
        "            # skip generating this sample if already in the log list\n",
        "            if sample_id in LOG_LIST:\n",
        "                  print(sample_id+\" already in log list\")\n",
        "                  continue\n",
        "            for s in range(S):\n",
        "                frame_num = (global_step-1)*S+s\n",
        "                fn = filenames[frame_num]\n",
        "                if s==0:\n",
        "                    print('start frame', fn)\n",
        "                im = imageio.imread(fn)\n",
        "                im = im.astype(np.uint8)\n",
        "                im = torch.from_numpy(im).permute(2,0,1)\n",
        "                rgbs.append(im)\n",
        "            rgbs = torch.stack(rgbs, dim=0).unsqueeze(0) # 1, S, C, H, W\n",
        "\n",
        "            with torch.no_grad():\n",
        "                trajs_e, vis_e = run_model(model, rgbs, N, split)\n",
        "\n",
        "            # store img0 and img1 (frame 1 and 8) and trajs_e, vis_e\n",
        "            print(vis_e)\n",
        "            save_data(sample_id, rgbs[0][0], rgbs[0][-1], trajs_e, vis_e)\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print('error', e)\n",
        "\n",
        "def img_to_array(tensor_img):\n",
        "   x = tensor_img.permute(1, 2, 0).numpy() # from tensor to numpy array\n",
        "   x = cv2.resize(x, (240, 120)) # resizing image\n",
        "   return x\n",
        "\n",
        "def save_data(sample_id, frame0, frame7, trajs, vis):\n",
        "  \"\"\"\n",
        "  Saving\n",
        "  - coordinates to COORDS_DIR as .npy files\n",
        "  - visibility of coordinates to VIS_DIR as .npy files\n",
        "  - 0th frames to FRAME0_DIR directory as .npy files\n",
        "  - 7th frames to FRAME7_DIR directory as .npy files\n",
        "  \n",
        "  - Coordinates, visibility and frames are mapped with sample_id, all sample_ids are stored in sample_ids.txt\n",
        "  \"\"\"\n",
        "  img0 = img_to_array(frame0) # transform first frame to array\n",
        "  img7 = img_to_array(frame7) # tranform last frame (8th) to array\n",
        "  coords = trajs.cpu().numpy()\n",
        "  vis = vis.cpu().numpy()\n",
        "\n",
        "  # Store coords, frame0, frame1\n",
        "  np.save(COORDS_DIR+sample_id, coords)\n",
        "  np.save(VIS_DIR+sample_id, vis)\n",
        "  np.save(FRAME0_DIR+sample_id, img0)\n",
        "  np.save(FRAME1_DIR+sample_id, img7)\n",
        "\n",
        "  # Add sample_id to log list\n",
        "  LOG_LIST.append(sample_id)\n",
        "  save_log(LOG_LIST)\n",
        "\n",
        "def save_log(log_list):\n",
        "  with open(LOG_FILE, \"w\") as outfile:\n",
        "    outfile.write(\"\\n\".join(log_list))"
      ],
      "metadata": {
        "id": "jWzwnNKZKFyj"
      },
      "id": "jWzwnNKZKFyj",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('reference_model')"
      ],
      "metadata": {
        "id": "LTZQnKzeKl6r",
        "outputId": "f3313b60-f415-403b-c837-e12db355e9fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LTZQnKzeKl6r",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading ckpt from reference_model\n",
            "...found checkpoint reference_model/model-000100000.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating directories and running generation of data"
      ],
      "metadata": {
        "id": "YYg8VkJJJh0P"
      },
      "id": "YYg8VkJJJh0P"
    },
    {
      "cell_type": "code",
      "source": [
        "# create a folder to store training data in\n",
        "!mkdir training_data\n",
        "!mkdir training_data/frame0/\n",
        "!mkdir training_data/frame1/\n",
        "!mkdir training_data/coords/\n",
        "!mkdir training_data/vis/\n",
        "!touch training_data/sample_ids.txt\n",
        "PATH = \"\""
      ],
      "metadata": {
        "id": "4cZ_q9I6tBNj"
      },
      "id": "4cZ_q9I6tBNj",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want to use an old training data folder\n",
        "# cp from drive to colab memory and unzip\n",
        "TRAIN_DATA_DIR = \"training_data_14122022\" # specify the name of the data folder located in drive\n",
        "!unzip -d \"$TRAIN_DATA_DIR\"/ /content/drive/MyDrive/\"$TRAIN_DATA_DIR\".zip # unziping frames\n",
        "PATH = TRAIN_DATA_DIR+\"/content/\""
      ],
      "metadata": {
        "id": "tApdIoeTvoDg"
      },
      "id": "tApdIoeTvoDg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANING_DATA_DIR = PATH+\"training_data/\"\n",
        "COORDS_DIR = PATH+\"training_data/coords/\"\n",
        "VIS_DIR = PATH+\"training_data/vis/\"\n",
        "FRAME0_DIR= PATH+\"training_data/frame0/\"\n",
        "FRAME1_DIR= PATH+\"training_data/frame1/\"\n",
        "LOG_FILE = PATH+\"training_data/sample_ids.txt\"\n",
        "LOG_LIST = open(LOG_FILE).read().splitlines()"
      ],
      "metadata": {
        "id": "lyp0MVe7uWwf"
      },
      "id": "lyp0MVe7uWwf",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_training_data(model, 'Tai chi10 forms 2009-KX-dEeB47sc', n=64)\n",
        "# generate_training_data(model, 'Tai chi陈式太极拳五十六式-vB8XTJfV4rY', n=64)\n",
        "# generate_training_data(model, 'Tai chiYang Family Tai Chi q&a Knee Brush-WPeVwAhTNuU', n=64)\n",
        "# generate_training_data(model, 'Tai chiWee Kee Jin - Keeping Your Structure-7jn9jeAbChE', n=64)\n",
        "# generate_training_data(model, 'Tai chi熊門楊家太極拳111式第一段\\u3000李國光老師示範-X_9SJZuSWQU', n=64)\n",
        "# generate_training_data(model, 'Tai chi56式夕陽美功夫扇-uOw-z7CR7x8', n=64)\n",
        "# generate_training_data(model, 'Tai chiRen Guang Yi - Chen Style Taiji silk reeling part II-Wh3AmDsdQtM', n=64)"
      ],
      "metadata": {
        "id": "lkF4vYMA7zvM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1bef0b-e9b8-4e32-def8-606e37fdef28"
      },
      "id": "lkF4vYMA7zvM",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample KX-dEeB47sc_0: step 1/235\n",
            "start frame frames/content/frames/Tai chi10 forms 2009-KX-dEeB47sc/frames/frame_00001.jpg\n",
            "rgbs (float32) min = 0.00, mean = 0.59, max = 199.60 torch.Size([1, 8, 3, 360, 640])\n",
            "vis_e (float32) min = -4.14, mean = 3.00, max = 11.26 torch.Size([1, 8, 4096])\n",
            "tensor([[ 2.3131, -0.0137,  1.5245,  ..., -0.7300, -4.1350, -3.1928]],\n",
            "       device='cuda:0')\n",
            "sample KX-dEeB47sc_8: step 2/235\n",
            "start frame frames/content/frames/Tai chi10 forms 2009-KX-dEeB47sc/frames/frame_00017.jpg\n",
            "rgbs (float32) min = 0.00, mean = 16.16, max = 217.67 torch.Size([1, 8, 3, 360, 640])\n",
            "vis_e (float32) min = -4.80, mean = 2.77, max = 12.48 torch.Size([1, 8, 4096])\n",
            "tensor([[ 0.7453,  1.7871,  0.2403,  ...,  1.1205, -0.0788, -1.1653]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of file names to go through\n",
        "videos_list = [f for f in os.listdir(DATA_DIR+'/content/frames/') if not f.startswith('.')]\n",
        "print(videos_list)"
      ],
      "metadata": {
        "id": "_DmrwfqCnJVH"
      },
      "id": "_DmrwfqCnJVH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through the videos list and generate training data files\n",
        "for x in range(len(videos_list)):\n",
        "  print(\"Now generating training data for {}, {} out of {}.\".format(videos_list[x], x, len(videos_list)))\n",
        "  generate_training_data(model, videos_list[x], 100)"
      ],
      "metadata": {
        "id": "6H_eyv85wZd3"
      },
      "id": "6H_eyv85wZd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zip data and store in Drive"
      ],
      "metadata": {
        "id": "y7K9XdyxJwAc"
      },
      "id": "y7K9XdyxJwAc"
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "TODAY = date.today()\n",
        "\n",
        "# zip training data\n",
        "!cd /content/\"$PATH\"training_data && zip -r /content/training_data_\"$TODAY\".zip .\n",
        "# cp NumPy zip file into drive\n",
        "!cp training_data_\"$TODAY\".zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "PH9XF70MulWV"
      },
      "id": "PH9XF70MulWV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}