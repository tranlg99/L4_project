{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Script for Generating Training Data from Frames using PIPs\n",
        "https://github.com/aharley/pips"
      ],
      "metadata": {
        "id": "7aDztnqsvgfZ"
      },
      "id": "7aDztnqsvgfZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial set up\n",
        "Connection to MyDrive, requirements, imports, downloading models weights"
      ],
      "metadata": {
        "id": "II3QRFFivngi"
      },
      "id": "II3QRFFivngi"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "239cca92",
      "metadata": {
        "id": "239cca92",
        "outputId": "7a1838f0-2b91-4a24-96af-93ddbd61c624",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connecting drive to colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing requirements\n",
        "!pip install imageio==2.19.3\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install einops==0.4.1\n",
        "!pip install scikit-learn==1.1.1\n",
        "!pip install matplotlib==3.5.1\n",
        "!pip install protobuf==3.20.0\n",
        "!pip install fire==0.4.0"
      ],
      "metadata": {
        "id": "daqRwkpfAq6L"
      },
      "id": "daqRwkpfAq6L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/drive_folder/pips')\n",
        "import time\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import saverloader\n",
        "from nets.pips import Pips\n",
        "import utils.improc\n",
        "import random\n",
        "import glob\n",
        "from utils.basic import print_, print_stats\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import imageio.v2 as imageio\n",
        "from csv import writer\n",
        "\n",
        "# save numpy array as npz file\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed"
      ],
      "metadata": {
        "id": "O_R-IzS1EPcy"
      },
      "id": "O_R-IzS1EPcy",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading their reference model\n",
        "!bash /content/drive/MyDrive/drive_folder/pips/get_reference_model.sh"
      ],
      "metadata": {
        "id": "VngwyXNrAuQd"
      },
      "id": "VngwyXNrAuQd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data to generate training data from"
      ],
      "metadata": {
        "id": "R9V-6CiZvycm"
      },
      "id": "R9V-6CiZvycm"
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"frames_small\" # specify the name of the data folder located in drive\n",
        "!unzip -d \"$DATA_DIR\"/ /content/drive/MyDrive/\"$DATA_DIR\".zip # unziping frames"
      ],
      "metadata": {
        "id": "lLBW0C-an9sl"
      },
      "id": "lLBW0C-an9sl",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating training data"
      ],
      "metadata": {
        "id": "qBTvq9aKwUkL"
      },
      "id": "qBTvq9aKwUkL"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PIPs implementation"
      ],
      "metadata": {
        "id": "Rp5xw41PJcEu"
      },
      "id": "Rp5xw41PJcEu"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_weights):\n",
        "  model = Pips(stride=4).cuda()\n",
        "  parameters = list(model.parameters())\n",
        "  _ = saverloader.load(model_weights, model)\n",
        "  global_step = 0\n",
        "  model.eval()\n",
        "  return model\n",
        "\n",
        "\n",
        "def run_model(model, rgbs, N, split):\n",
        "    rgbs = rgbs.cuda().float() # B, S, C, H, W\n",
        "\n",
        "    B, S, C, H, W = rgbs.shape\n",
        "    rgbs_ = rgbs.reshape(B*S, C, H, W)\n",
        "    H_, W_ = 360, 640\n",
        "    rgbs_ = F.interpolate(rgbs_, (H_, W_), mode='bilinear')\n",
        "    H, W = H_, W_\n",
        "    rgbs = rgbs_.reshape(B, S, C, H, W)\n",
        "\n",
        "    # pick N points to track; we'll use a uniform grid\n",
        "    N_ = np.sqrt(N).round().astype(np.int32)\n",
        "    grid_y, grid_x = utils.basic.meshgrid2d(B, N_, N_, stack=False, norm=False, device='cuda')\n",
        "    grid_y = 8 + grid_y.reshape(B, -1)/float(N_-1) * (H-16)\n",
        "    grid_x = 8 + grid_x.reshape(B, -1)/float(N_-1) * (W-16)\n",
        "    xy = torch.stack([grid_x, grid_y], dim=-1) # B, N_*N_, 2\n",
        "    _, S, C, H, W = rgbs.shape\n",
        "\n",
        "    print_stats('rgbs', rgbs)\n",
        "\n",
        "    # splitting grid of points into tensors of size 1500 along dim=1\n",
        "    if split:\n",
        "       xy_split = torch.split(xy, 1500, dim=1)\n",
        "       preds_split = []\n",
        "\n",
        "      # for each splitted point compute trajs\n",
        "       for i in range(len(xy_split)):\n",
        "         preds, preds_anim, vis_e, stats = model(xy_split[i], rgbs, iters=6)      \n",
        "         preds_split.append(preds[-1])\n",
        "\n",
        "       # put trajs back together\n",
        "       trajs_e = torch.cat(preds_split, 2)\n",
        "       \n",
        "\n",
        "    else:\n",
        "      preds, preds_anim, vis_e, stats = model(xy, rgbs, iters=6)\n",
        "      # preds is a list of torch tensors \n",
        "      trajs_e = preds[-1] # tensor of shape (frames, tracking points, 2)\n",
        "    print_stats('trajs_e', trajs_e)\n",
        "\n",
        "    # return vis?? as well\n",
        "    return trajs_e[:,-1,:,:]\n",
        "\n",
        "def generate_training_data(pips_model, video_name, n, split=True):\n",
        "    model = pips_model\n",
        "    \n",
        "    ## Choose hyps\n",
        "    B = 1\n",
        "    S = 8\n",
        "    N = n**2 # number of points to track\n",
        "\n",
        "    # Get frames of a file\n",
        "    filenames = glob.glob(DATA_DIR+'/content/frames/'+video_name+'/frames/*.jpg')\n",
        "    filenames = sorted(filenames)\n",
        "\n",
        "    # Remove every second frame from a list\n",
        "    n = 2\n",
        "    del filenames[n - 1::n]\n",
        "\n",
        "    max_iters = len(filenames)//S # run each unique subsequence\n",
        "    iters = 100\n",
        "    global_step = 0\n",
        "\n",
        "    # Run model each of 8 frames\n",
        "    while global_step < iters:\n",
        "        global_step += 1\n",
        "        \n",
        "        try:\n",
        "            rgbs = []\n",
        "            sample_id = video_name[-11:]+\"_\"+str((global_step-1)*S)\n",
        "            print(\"sample {}: step {}/{}\".format(sample_id, global_step, max_iters))\n",
        "\n",
        "            # skip generating this sample if already in the log list\n",
        "            if sample_id in LOG_LIST:\n",
        "                  print(sample_id+\" already in log list\")\n",
        "                  continue\n",
        "            for s in range(S):\n",
        "                frame_num = (global_step-1)*S+s\n",
        "                fn = filenames[frame_num]\n",
        "                if s==0:\n",
        "                    print('start frame', fn)\n",
        "                im = imageio.imread(fn)\n",
        "                im = im.astype(np.uint8)\n",
        "                # print(im.shape)\n",
        "                im = torch.from_numpy(im).permute(2,0,1)\n",
        "                # print(im.shape)\n",
        "                rgbs.append(im)\n",
        "            rgbs = torch.stack(rgbs, dim=0).unsqueeze(0) # 1, S, C, H, W\n",
        "\n",
        "            with torch.no_grad():\n",
        "                trajs_e = run_model(model, rgbs, N, split)\n",
        "\n",
        "            # store img0 and img1 (frame 1 and 8) and trajs_e\n",
        "            save_data(sample_id, rgbs[0][0], rgbs[0][-1], trajs_e)\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print('error', e)\n",
        "\n",
        "def img_to_array(tensor_img):\n",
        "   x = tensor_img.permute(1, 2, 0).numpy() # from tensor to numpy array\n",
        "   x = cv2.resize(x, (240, 120)) # resizing image\n",
        "   return x\n",
        "\n",
        "def save_data(sample_id, frame0, frame7, trajs):\n",
        "  \"\"\"\n",
        "  Saving coordinates to or COORDS_DIR as .npy files or all together as CSV_FILE file???\n",
        "  Saving 0th frames to FRAME0_DIR directory as .npy files\n",
        "  Saving 7th frames to FRAME7_DIR directory as .npy files\n",
        "  - Coordinates and frames are mapped with sample_id, all sample_ids are stored in sample_ids.txt\n",
        "  \"\"\"\n",
        "  img0 = img_to_array(frame0) # transform first frame to array\n",
        "  img7 = img_to_array(frame7) # tranform last frame (8th) to array\n",
        "  coords = trajs.cpu().numpy()\n",
        "\n",
        "  # Store coords, frame0, frame1\n",
        "  np.save(COORDS_DIR+sample_id, coords)\n",
        "  np.save(FRAME0_DIR+sample_id, img0)\n",
        "  np.save(FRAME1_DIR+sample_id, img7)\n",
        "\n",
        "  # Add sample_id to log list\n",
        "  LOG_LIST.append(sample_id)\n",
        "  save_log(LOG_LIST)\n",
        "\n",
        "def save_log(log_list):\n",
        "  with open(LOG_FILE, \"w\") as outfile:\n",
        "    outfile.write(\"\\n\".join(log_list))"
      ],
      "metadata": {
        "id": "jWzwnNKZKFyj"
      },
      "id": "jWzwnNKZKFyj",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model('reference_model')"
      ],
      "metadata": {
        "id": "LTZQnKzeKl6r",
        "outputId": "41fb928d-e149-4fda-83aa-7f6bd8cb6deb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LTZQnKzeKl6r",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading ckpt from reference_model\n",
            "...found checkpoint reference_model/model-000100000.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating directories and running generation of data"
      ],
      "metadata": {
        "id": "YYg8VkJJJh0P"
      },
      "id": "YYg8VkJJJh0P"
    },
    {
      "cell_type": "code",
      "source": [
        "#create a folder to store training data in\n",
        "!mkdir training_data\n",
        "!mkdir training_data/frame0/\n",
        "!mkdir training_data/frame1/\n",
        "!mkdir training_data/coords/\n",
        "!touch training_data/sample_ids.txt\n",
        "PATH = \"\""
      ],
      "metadata": {
        "id": "4cZ_q9I6tBNj"
      },
      "id": "4cZ_q9I6tBNj",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if training data folder already exists cp from drive to colab memory and unzip\n",
        "TRAIN_DATA_DIR = \"training_data_12122022\" # specify the name of the data folder located in drive\n",
        "!unzip -d \"$TRAIN_DATA_DIR\"/ /content/drive/MyDrive/\"$TRAIN_DATA_DIR\".zip # unziping frames\n",
        "PATH = \"training_data_01122022/content/\""
      ],
      "metadata": {
        "id": "tApdIoeTvoDg"
      },
      "id": "tApdIoeTvoDg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRANING_DATA_DIR = PATH+\"training_data/\"\n",
        "COORDS_DIR = PATH+\"training_data/coords/\"\n",
        "FRAME0_DIR= PATH+\"training_data/frame0/\"\n",
        "FRAME1_DIR= PATH+\"training_data/frame1/\"\n",
        "LOG_FILE = PATH+\"training_data/sample_ids.txt\"\n",
        "LOG_LIST = open(LOG_FILE).read().splitlines()"
      ],
      "metadata": {
        "id": "lyp0MVe7uWwf"
      },
      "id": "lyp0MVe7uWwf",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_training_data(model, 'Tai chi10 forms 2009-KX-dEeB47sc', n=64)\n",
        "generate_training_data(model, 'Tai chi陈式太极拳五十六式-vB8XTJfV4rY', n=64)\n",
        "generate_training_data(model, 'Tai chiYang Family Tai Chi q&a Knee Brush-WPeVwAhTNuU', n=64)\n",
        "generate_training_data(model, 'Tai chiWee Kee Jin - Keeping Your Structure-7jn9jeAbChE', n=64)\n",
        "generate_training_data(model, 'Tai chi熊門楊家太極拳111式第一段\\u3000李國光老師示範-X_9SJZuSWQU', n=64)\n",
        "generate_training_data(model, 'Tai chi56式夕陽美功夫扇-uOw-z7CR7x8', n=64)"
      ],
      "metadata": {
        "id": "lkF4vYMA7zvM"
      },
      "id": "lkF4vYMA7zvM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of file names to go through\n",
        "videos_list = [f for f in os.listdir('frames_small/content/frames/') if not f.startswith('.')]\n",
        "print(videos_list)"
      ],
      "metadata": {
        "id": "_DmrwfqCnJVH",
        "outputId": "86489ea8-6ed0-45f9-c2d3-3a4e80369669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_DmrwfqCnJVH",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tai chiCanda - Tai Chi Chuan Yang-Stil - Sanfte Bewegungsformen für Einsteiger-f7NkWPgh1-o', 'Tai chiWee Kee Jin - Keeping Your Structure-7jn9jeAbChE', 'Tai chiYang Family Tai Chi q&a Knee Brush-WPeVwAhTNuU', 'Tai chi熊門楊家太極拳111式第一段\\u3000李國光老師示範-X_9SJZuSWQU', 'Tai chi10 forms 2009-KX-dEeB47sc', 'Tai chi陈式太极拳五十六式-vB8XTJfV4rY', 'Tai chiShaolin Basics Are From Theater!-gyms4lomW50', 'Tai chiRen Guang Yi - Chen Style Taiji silk reeling part II-Wh3AmDsdQtM', 'Tai chi56式夕陽美功夫扇-uOw-z7CR7x8', 'Tai chiCurso Chi Kung de los Seis Sonidos Curativos-PvjYVsRK4Dg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# iterate through the videos list and generate training data files\n",
        "for x in range(len(videos_list)):\n",
        "  print(\"Now generating training data for {}, {} out of {}.\".format(videos_list[x], x, len(videos_list)))\n",
        "  generate_training_data(model, videos_list[x], 100)"
      ],
      "metadata": {
        "id": "6H_eyv85wZd3"
      },
      "id": "6H_eyv85wZd3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zip data and store in Drive"
      ],
      "metadata": {
        "id": "y7K9XdyxJwAc"
      },
      "id": "y7K9XdyxJwAc"
    },
    {
      "cell_type": "code",
      "source": [
        "# zip training data\n",
        "!zip -r /content/training_data_12122022.zip /content/training_data -x \"*/.*\"\n",
        "# cp NumPy zip file into drive\n",
        "!cp training_data_06122022.zip /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "PH9XF70MulWV"
      },
      "id": "PH9XF70MulWV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "W5KEucYqJUXz"
      },
      "id": "W5KEucYqJUXz"
    },
    {
      "cell_type": "code",
      "source": [
        "# see training data of one video for verification\n",
        "from numpy import load\n",
        "data = load('training_data/coords/Wh3AmDsdQtM0.npy', allow_pickle=True)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "ZAJ1hanTBl2C",
        "outputId": "637befcd-22b8-45f1-c899-8ba58dab487c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZAJ1hanTBl2C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 10000, 2)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}